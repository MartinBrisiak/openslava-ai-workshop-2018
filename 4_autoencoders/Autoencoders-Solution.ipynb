{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders\n",
    "\n",
    "In this notebook we'll try something more advanced - we are going to learn about a special type of a neural network called Autoencoder. Lets first make the imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Conv2D, Flatten, Reshape, Conv2DTranspose, Activation, LSTM\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset\n",
    "\n",
    "We will again use our well known MNIST dataset, so lets load it first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look on how the images look like, e.g. from the testing set. Each image is 28 x 28 pixels size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets draw some images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb20425e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image label: 9\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "\n",
    "image_num = random.randint(0, len(x_train))\n",
    "img = x_train[image_num]\n",
    "\n",
    "img = img.reshape(image_size, image_size)\n",
    "\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.imshow(img, interpolation='none', cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(\"Image label: {}\".format(y_train[image_num]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoders are very interesitng variation of a neural network. In a typical neural network, we have some input data features, based on which we want to predict the labels. So a typical neural network does an aproximation of some function f:\n",
    "\n",
    "$$\n",
    "f(x) = y\n",
    "$$\n",
    "\n",
    "All of the examples we have shown you before actually use this kind of architecture and do predictions.\n",
    "\n",
    "Autoencoder is different, with autoencoder you are actually trying to predict the same data as you got on the input:\n",
    "\n",
    "$$\n",
    "f(x) = x\n",
    "$$\n",
    "\n",
    "Why would you do such a thing? Well let's first look at the autoencoder typical architecture. \n",
    "\n",
    "```\n",
    "               (x)                       (x)\n",
    "        \n",
    "               (x)          (x)          (x)\n",
    "        \n",
    "input =======> (x) =======> (x) =======> (x) =======> input'\n",
    "        \n",
    "               (x)          (x)          (x)\n",
    "        \n",
    "               (x)                       (x)\n",
    "           \n",
    "             encoder    hidden state   decoder\n",
    "```\n",
    "\n",
    "There couple important things here - as explained earlier, during the training the autoencoder is using the same input and output data - it's trying to predict the input from itself. This is done by composing two neural networks - an encoder network and decoder network. Typically the output of the encoder has lower dimensionality than the input itself - it is in some form a compressed representation of the input. But you can also view this as a representation of the most important part of the input, that can be used to reconstruct it back.\n",
    "\n",
    "You can use different network architectures for both encoder and decoder. For example for image tasks, convolutional layers are common, for sequence based tasks (text processing and similar) recurent layers are typically used.\n",
    "\n",
    "What you can use autoencoder for some very specific tasks, for example:\n",
    "- create a compressed representation of the input, that can be used to reconstruct it (though this is a very bad compression algorithm, as it can compress only very specific data)\n",
    "- because the autoencoder learns the most important part of the input, it can be actually used for removing the noise from the data - e.g. denoising the images\n",
    "- autoencoders can be used for detecting anomalies in the data, such as frauds in financial transactions, or iot sensor malfunction. This is because they can learn how \"normal\" data look like, and if the predicted output differs from the input, we can consider it as anomaly.\n",
    "\n",
    "As an example for autoencoder we will show how to denoise images from MNIST.\n",
    "\n",
    "We will use already loaded data, we just need to reshape it back to 28 x 28 pixels, as we are going to use convolutional layers this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, [-1, image_size, image_size, 1]) / 255\n",
    "x_test = np.reshape(x_test, [-1, image_size, image_size, 1]) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to add some random noise to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise = np.random.normal(loc=0.5, scale=0.5, size=x_train.shape)\n",
    "x_train_noisy = x_train + noise\n",
    "noise = np.random.normal(loc=0.5, scale=0.5, size=x_test.shape)\n",
    "x_test_noisy = x_test + noise\n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a transformed dataset, lets draw some samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nc2kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1052b04e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image labels: 5\n"
     ]
    }
   ],
   "source": [
    "image_index = random.randint(0, len(x_train_noisy))\n",
    "img = x_train_noisy[image_index]\n",
    "img.shape\n",
    "img_plt = img.reshape(image_size, image_size\n",
    "                    )\n",
    "img_plt = (img_plt * 255).astype(np.uint8)\n",
    "\n",
    "plt.imshow(img_plt, interpolation='none', cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(\"Image labels: {}\".format(y_train[image_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create an encoder with convolutional layers that are going to create a hidden representation of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (image_size, image_size, 1)\n",
    "batch_size = 128\n",
    "kernel_size = 3\n",
    "latent_dim = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here the convolutional layers that are transforming the image to smaller and smaller sizes - you will need to code the oposite transformation in the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoder\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = inputs\n",
    "\n",
    "x = Conv2D(filters=32,\n",
    "               kernel_size=kernel_size,\n",
    "               strides=2,\n",
    "               activation='relu',\n",
    "               padding='same')(x)\n",
    "x = Conv2D(filters=64,\n",
    "               kernel_size=kernel_size,\n",
    "               strides=2,\n",
    "               activation='relu',\n",
    "               padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "latent_vector (Dense)        (None, 16)                50192     \n",
      "=================================================================\n",
      "Total params: 69,008\n",
      "Trainable params: 69,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Shape info needed to build Decoder Model\n",
    "shape = K.int_shape(x)\n",
    "\n",
    "# Generate the latent vector\n",
    "x = Flatten()(x)\n",
    "latent = Dense(latent_dim, name='latent_vector')(x)\n",
    "\n",
    "# Instantiate Encoder Model\n",
    "encoder = Model(inputs, latent, name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the output of the encoder is just 16 values - much less than original 784. Now lets create a decoder from this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
    "x = Dense(shape[1] * shape[2] * shape[3])(latent_inputs)\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your turn now, define the decoder convolutional layers - they have similar parameters as the two layers above, just you need to use Conv2DTranspose layer instead of Conv2D and reverse the filter numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Conv2DTranspose(filters=64,\n",
    "               kernel_size=kernel_size,\n",
    "               strides=2,\n",
    "               activation='relu',\n",
    "               padding='same')(x)\n",
    "x = Conv2DTranspose(filters=32,\n",
    "               kernel_size=kernel_size,\n",
    "               strides=2,\n",
    "               activation='relu',\n",
    "               padding='same')(x)\n",
    "\n",
    "# x = Conv2DTranspose(filters=64,\n",
    "#                         kernel_size=kernel_size,\n",
    "#                         strides=2,\n",
    "#                         activation='relu',\n",
    "#                         padding='same')(x)\n",
    "# x = Conv2DTranspose(filters=32,\n",
    "#                         kernel_size=kernel_size,\n",
    "#                         strides=2,\n",
    "#                         activation='relu',\n",
    "#                         padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3136)              53312     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         289       \n",
      "_________________________________________________________________\n",
      "decoder_output (Activation)  (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 108,993\n",
      "Trainable params: 108,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = Conv2DTranspose(filters=1,\n",
    "                    kernel_size=kernel_size,\n",
    "                    padding='same')(x)\n",
    "\n",
    "outputs = Activation('sigmoid', name='decoder_output')(x)\n",
    "\n",
    "# Instantiate Decoder Model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model (we can also show a summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 16)                69008     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         108993    \n",
      "=================================================================\n",
      "Total params: 178,001\n",
      "Trainable params: 178,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.0661 - val_loss: 0.0376\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 59s 985us/step - loss: 0.0277 - val_loss: 0.0223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb45869a58>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\n",
    "autoencoder.summary()\n",
    "\n",
    "autoencoder.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(x_train_noisy,\n",
    "                x_train,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                epochs=2,\n",
    "                batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And make predictions on the whole test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_decoded = autoencoder.predict(x_test_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now show the picture after denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb45dcd400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVK80HAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb2399c240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = random.randint(0, len(x_test_noisy))\n",
    "img = x_test_noisy[index]\n",
    "img_plt = img.reshape(image_size, image_size)\n",
    "img_plt = (img_plt * 255).astype(np.uint8)\n",
    "\n",
    "plt.imshow(img_plt, interpolation='none', cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "img = x_decoded[index]\n",
    "img_plt = img.reshape(image_size, image_size)\n",
    "img_plt = (img_plt * 255).astype(np.uint8)\n",
    "\n",
    "plt.imshow(img_plt, interpolation='none', cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
