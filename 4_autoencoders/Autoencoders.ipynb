{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders\n",
    "\n",
    "In this notebook we'll try something more advanced - we are going to learn about a special type of a neural network called Autoencoder. Lets first make the imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Conv2D, Flatten, Reshape, Conv2DTranspose, Activation, LSTM\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset\n",
    "\n",
    "We will again use our well known MNIST dataset, so lets load it first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look on how the images look like, e.g. from the testing set. Each image is 28 x 28 pixels size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets draw some images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "\n",
    "image_num = random.randint(0, len(x_train))\n",
    "img = x_train[image_num]\n",
    "\n",
    "img = img.reshape(image_size, image_size)\n",
    "\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.imshow(img, interpolation='none', cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(\"Image label: {}\".format(y_train[image_num]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoders are very interesitng variation of a neural network. In a typical neural network, we have some input data features, based on which we want to predict the labels. So a typical neural network does an aproximation of some function f:\n",
    "\n",
    "$$\n",
    "f(x) = y\n",
    "$$\n",
    "\n",
    "All of the examples we have shown you before actually use this kind of architecture and do predictions.\n",
    "\n",
    "Autoencoder is different, with autoencoder you are actually trying to predict the same data as you got on the input:\n",
    "\n",
    "$$\n",
    "f(x) = x\n",
    "$$\n",
    "\n",
    "Why would you do such a thing? Well let's first look at the autoencoder typical architecture. \n",
    "\n",
    "```\n",
    "               (x)                       (x)\n",
    "        \n",
    "               (x)          (x)          (x)\n",
    "        \n",
    "input =======> (x) =======> (x) =======> (x) =======> input'\n",
    "        \n",
    "               (x)          (x)          (x)\n",
    "        \n",
    "               (x)                       (x)\n",
    "           \n",
    "             encoder    hidden state   decoder\n",
    "```\n",
    "\n",
    "There couple important things here - as explained earlier, during the training the autoencoder is using the same input and output data - it's trying to predict the input from itself. This is done by composing two neural networks - an encoder network and decoder network. Typically the output of the encoder has lower dimensionality than the input itself - it is in some form a compressed representation of the input. But you can also view this as a representation of the most important part of the input, that can be used to reconstruct it back.\n",
    "\n",
    "You can use different network architectures for both encoder and decoder. For example for image tasks, convolutional layers are common, for sequence based tasks (text processing and similar) recurent layers are typically used.\n",
    "\n",
    "What you can use autoencoder for some very specific tasks, for example:\n",
    "- create a compressed representation of the input, that can be used to reconstruct it (though this is a very bad compression algorithm, as it can compress only very specific data)\n",
    "- because the autoencoder learns the most important part of the input, it can be actually used for removing the noise from the data - e.g. denoising the images\n",
    "- autoencoders can be used for detecting anomalies in the data, such as frauds in financial transactions, or iot sensor malfunction. This is because they can learn how \"normal\" data look like, and if the predicted output differs from the input, we can consider it as anomaly.\n",
    "\n",
    "As an example for autoencoder we will show how to denoise images from MNIST.\n",
    "\n",
    "We will use already loaded data, we just need to reshape it back to 28 x 28 pixels, as we are going to use convolutional layers this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, [-1, image_size, image_size, 1]) / 255\n",
    "x_test = np.reshape(x_test, [-1, image_size, image_size, 1]) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to add some random noise to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise = np.random.normal(loc=0.5, scale=0.5, size=x_train.shape)\n",
    "x_train_noisy = x_train + noise\n",
    "noise = np.random.normal(loc=0.5, scale=0.5, size=x_test.shape)\n",
    "x_test_noisy = x_test + noise\n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a transformed dataset, lets draw some samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = random.randint(0, len(x_train_noisy))\n",
    "img = x_train_noisy[image_index]\n",
    "img.shape\n",
    "img_plt = img.reshape(image_size, image_size\n",
    "                    )\n",
    "img_plt = (img_plt * 255).astype(np.uint8)\n",
    "\n",
    "plt.imshow(img_plt, interpolation='none', cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(\"Image labels: {}\".format(y_train[image_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create an encoder with convolutional layers that are going to create a hidden representation of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (image_size, image_size, 1)\n",
    "batch_size = 128\n",
    "kernel_size = 3\n",
    "latent_dim = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here the convolutional layers that are transforming the image to smaller and smaller sizes - you will need to code the oposite transformation in the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoder\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = inputs\n",
    "\n",
    "x = Conv2D(filters=32,\n",
    "               kernel_size=kernel_size,\n",
    "               strides=2,\n",
    "               activation='relu',\n",
    "               padding='same')(x)\n",
    "x = Conv2D(filters=64,\n",
    "               kernel_size=kernel_size,\n",
    "               strides=2,\n",
    "               activation='relu',\n",
    "               padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape info needed to build Decoder Model\n",
    "shape = K.int_shape(x)\n",
    "\n",
    "# Generate the latent vector\n",
    "x = Flatten()(x)\n",
    "latent = Dense(latent_dim, name='latent_vector')(x)\n",
    "\n",
    "# Instantiate Encoder Model\n",
    "encoder = Model(inputs, latent, name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the output of the encoder is just 16 values - much less than original 784. Now lets create a decoder from this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
    "x = Dense(shape[1] * shape[2] * shape[3])(latent_inputs)\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your turn now, define the decoder convolutional layers - they have similar parameters as the two layers above, just you need to use Conv2DTranspose layer instead of Conv2D and reverse the filter numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO define two decoder convolutional layers, they should look exactly the same as in encoder, just swapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Conv2DTranspose(filters=1,\n",
    "                    kernel_size=kernel_size,\n",
    "                    padding='same')(x)\n",
    "\n",
    "outputs = Activation('sigmoid', name='decoder_output')(x)\n",
    "\n",
    "# Instantiate Decoder Model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model (we can also show a summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\n",
    "autoencoder.summary()\n",
    "\n",
    "autoencoder.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(x_train_noisy,\n",
    "                x_train,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                epochs=2,\n",
    "                batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And make predictions on the whole test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_decoded = autoencoder.predict(x_test_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now show the picture after denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = random.randint(0, len(x_test_noisy))\n",
    "img = x_test_noisy[index]\n",
    "img_plt = img.reshape(image_size, image_size)\n",
    "img_plt = (img_plt * 255).astype(np.uint8)\n",
    "\n",
    "plt.imshow(img_plt, interpolation='none', cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "img = x_decoded[index]\n",
    "img_plt = img.reshape(image_size, image_size)\n",
    "img_plt = (img_plt * 255).astype(np.uint8)\n",
    "\n",
    "plt.imshow(img_plt, interpolation='none', cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
