{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other neural network examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will show a couple of other examples for neural networks, these are more advanced though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Conv2D, Flatten, Reshape, Conv2DTranspose, Activation, LSTM, Conv1D, GlobalMaxPooling1D, Embedding\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras.datasets import imdb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence prediction with LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks can also work with sequences. Sequences are typically modeled with Recurent Neural Networks. These have connections between neurons within one layer, allowing them to preserve state from before and use it in the next prediction. Lets load and explore some data first.\n",
    "\n",
    "You can find more datasets at https://datamarket.com/data/list/?q=cat:g22%20provider:tsdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset = np.loadtxt('datasets/normalized_apple_prices.csv')\n",
    "dataset = np.loadtxt('datasets/ibm-common-stock-closing-prices-.csv', usecols=(1,), skiprows=1, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to scale the data into interval 0 - 1, to help the neural network optimize for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.reshape(-1, 1)\n",
    "# dataset_2.shape\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(dataset)\n",
    "dataset = scaler.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1a27f7d6a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a27ec7da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets take a look at our time series\n",
    "plt.plot(dataset)\n",
    "plt.xlabel('time period')\n",
    "plt.ylabel('normalized series value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to preprocess our dataset, with the following idea in mind:\n",
    "1. The neural network will take small part of the sequence (e.g. 7 continuous values) as input\n",
    "2. It will predict the next value based on this window\n",
    "\n",
    "Therefore we take the dataset, make the windows and expected predictions for each window (the next number in the sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_size = 7\n",
    "X = np.array([dataset[i:i+window_size] for i in range(0, len(dataset) - window_size)])\n",
    "y = np.array([dataset[i] for i in range(7, len(dataset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.31428571]\n",
      " [0.33571429]\n",
      " [0.35      ]\n",
      " [0.32857143]\n",
      " [0.35714286]\n",
      " [0.37142857]\n",
      " [0.37857143]]\n",
      "[0.37857143]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.35      ]\n",
      " [0.32857143]\n",
      " [0.35714286]\n",
      " [0.37142857]\n",
      " [0.37857143]\n",
      " [0.37857143]\n",
      " [0.41428571]]\n",
      "[0.27857143]\n"
     ]
    }
   ],
   "source": [
    "print(X[2])\n",
    "print(y[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_split = int(np.ceil(2*len(y)/float(3)))   # set the split point\n",
    "\n",
    "# partition the training set\n",
    "X_train = X[:train_test_split]\n",
    "y_train = y[:train_test_split]\n",
    "\n",
    "# keep the last chunk for testing\n",
    "X_test = X[train_test_split:]\n",
    "y_test = y[train_test_split:]\n",
    "\n",
    "# reshape the imput for LSTM layer [samples, window size, stepsize] \n",
    "X_train = np.asarray(np.reshape(X_train, (X_train.shape[0], window_size, 1)))\n",
    "X_test = np.asarray(np.reshape(X_test, (X_test.shape[0], window_size, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(5, input_shape=(window_size, 1)))\n",
    "model.add(Dense(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build model using keras documentation recommended optimizer initialization\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "166/166 [==============================] - 1s 5ms/step - loss: 0.0225\n",
      "Epoch 2/1000\n",
      "166/166 [==============================] - 0s 238us/step - loss: 0.0145\n",
      "Epoch 3/1000\n",
      "166/166 [==============================] - 0s 238us/step - loss: 0.0105\n",
      "Epoch 4/1000\n",
      "166/166 [==============================] - 0s 236us/step - loss: 0.0080\n",
      "Epoch 5/1000\n",
      "166/166 [==============================] - 0s 238us/step - loss: 0.0064\n",
      "Epoch 6/1000\n",
      "166/166 [==============================] - 0s 233us/step - loss: 0.0053\n",
      "Epoch 7/1000\n",
      "166/166 [==============================] - 0s 227us/step - loss: 0.0046\n",
      "Epoch 8/1000\n",
      "166/166 [==============================] - 0s 246us/step - loss: 0.0041\n",
      "Epoch 9/1000\n",
      "166/166 [==============================] - 0s 240us/step - loss: 0.0038\n",
      "Epoch 10/1000\n",
      "166/166 [==============================] - 0s 229us/step - loss: 0.0036\n",
      "Epoch 11/1000\n",
      "166/166 [==============================] - 0s 233us/step - loss: 0.0035\n",
      "Epoch 12/1000\n",
      "166/166 [==============================] - 0s 237us/step - loss: 0.0034\n",
      "Epoch 13/1000\n",
      "166/166 [==============================] - 0s 235us/step - loss: 0.0032\n",
      "Epoch 14/1000\n",
      "166/166 [==============================] - 0s 237us/step - loss: 0.0031\n",
      "Epoch 15/1000\n",
      "166/166 [==============================] - 0s 241us/step - loss: 0.0030\n",
      "Epoch 16/1000\n",
      "166/166 [==============================] - 0s 235us/step - loss: 0.0029\n",
      "Epoch 17/1000\n",
      "166/166 [==============================] - 0s 239us/step - loss: 0.0027\n",
      "Epoch 18/1000\n",
      "166/166 [==============================] - 0s 237us/step - loss: 0.0025\n",
      "Epoch 19/1000\n",
      "166/166 [==============================] - 0s 242us/step - loss: 0.0024\n",
      "Epoch 20/1000\n",
      "166/166 [==============================] - 0s 232us/step - loss: 0.0023\n",
      "Epoch 21/1000\n",
      "166/166 [==============================] - 0s 237us/step - loss: 0.0021\n",
      "Epoch 22/1000\n",
      "166/166 [==============================] - 0s 240us/step - loss: 0.0021\n",
      "Epoch 23/1000\n",
      "166/166 [==============================] - 0s 242us/step - loss: 0.0020\n",
      "Epoch 24/1000\n",
      "166/166 [==============================] - 0s 220us/step - loss: 0.0019\n",
      "Epoch 25/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0019\n",
      "Epoch 26/1000\n",
      "166/166 [==============================] - 0s 201us/step - loss: 0.0018\n",
      "Epoch 27/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0018\n",
      "Epoch 28/1000\n",
      "166/166 [==============================] - 0s 195us/step - loss: 0.0018\n",
      "Epoch 29/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0017\n",
      "Epoch 30/1000\n",
      "166/166 [==============================] - 0s 195us/step - loss: 0.0017\n",
      "Epoch 31/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0017\n",
      "Epoch 32/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0017\n",
      "Epoch 33/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0017\n",
      "Epoch 34/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0017\n",
      "Epoch 35/1000\n",
      "166/166 [==============================] - 0s 200us/step - loss: 0.0016\n",
      "Epoch 36/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0016\n",
      "Epoch 37/1000\n",
      "166/166 [==============================] - 0s 203us/step - loss: 0.0016\n",
      "Epoch 38/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0016\n",
      "Epoch 39/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0016\n",
      "Epoch 40/1000\n",
      "166/166 [==============================] - 0s 200us/step - loss: 0.0017\n",
      "Epoch 41/1000\n",
      "166/166 [==============================] - 0s 196us/step - loss: 0.0016\n",
      "Epoch 42/1000\n",
      "166/166 [==============================] - 0s 200us/step - loss: 0.0016\n",
      "Epoch 43/1000\n",
      "166/166 [==============================] - 0s 203us/step - loss: 0.0016\n",
      "Epoch 44/1000\n",
      "166/166 [==============================] - 0s 197us/step - loss: 0.0016\n",
      "Epoch 45/1000\n",
      "166/166 [==============================] - 0s 194us/step - loss: 0.0016\n",
      "Epoch 46/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0017\n",
      "Epoch 47/1000\n",
      "166/166 [==============================] - 0s 204us/step - loss: 0.0016\n",
      "Epoch 48/1000\n",
      "166/166 [==============================] - 0s 198us/step - loss: 0.0016\n",
      "Epoch 49/1000\n",
      "166/166 [==============================] - 0s 203us/step - loss: 0.0016\n",
      "Epoch 50/1000\n",
      "166/166 [==============================] - 0s 199us/step - loss: 0.0016\n",
      "Epoch 51/1000\n",
      "166/166 [==============================] - 0s 198us/step - loss: 0.0016\n",
      "Epoch 52/1000\n",
      "166/166 [==============================] - 0s 223us/step - loss: 0.0016\n",
      "Epoch 53/1000\n",
      "166/166 [==============================] - 0s 221us/step - loss: 0.0015\n",
      "Epoch 54/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0015\n",
      "Epoch 55/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0016\n",
      "Epoch 56/1000\n",
      "166/166 [==============================] - 0s 225us/step - loss: 0.0015\n",
      "Epoch 57/1000\n",
      "166/166 [==============================] - 0s 222us/step - loss: 0.0015\n",
      "Epoch 58/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0015\n",
      "Epoch 59/1000\n",
      "166/166 [==============================] - 0s 201us/step - loss: 0.0015\n",
      "Epoch 60/1000\n",
      "166/166 [==============================] - 0s 204us/step - loss: 0.0016\n",
      "Epoch 61/1000\n",
      "166/166 [==============================] - 0s 203us/step - loss: 0.0016\n",
      "Epoch 62/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0015\n",
      "Epoch 63/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0015\n",
      "Epoch 64/1000\n",
      "166/166 [==============================] - 0s 202us/step - loss: 0.0015\n",
      "Epoch 65/1000\n",
      "166/166 [==============================] - 0s 197us/step - loss: 0.0015\n",
      "Epoch 66/1000\n",
      "166/166 [==============================] - 0s 195us/step - loss: 0.0015\n",
      "Epoch 67/1000\n",
      "166/166 [==============================] - 0s 193us/step - loss: 0.0015\n",
      "Epoch 68/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0015\n",
      "Epoch 69/1000\n",
      "166/166 [==============================] - 0s 225us/step - loss: 0.0015\n",
      "Epoch 70/1000\n",
      "166/166 [==============================] - 0s 223us/step - loss: 0.0015\n",
      "Epoch 71/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0015\n",
      "Epoch 72/1000\n",
      "166/166 [==============================] - 0s 220us/step - loss: 0.0015\n",
      "Epoch 73/1000\n",
      "166/166 [==============================] - 0s 223us/step - loss: 0.0015\n",
      "Epoch 74/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0015\n",
      "Epoch 75/1000\n",
      "166/166 [==============================] - 0s 225us/step - loss: 0.0015\n",
      "Epoch 76/1000\n",
      "166/166 [==============================] - 0s 234us/step - loss: 0.0016\n",
      "Epoch 77/1000\n",
      "166/166 [==============================] - 0s 228us/step - loss: 0.0015\n",
      "Epoch 78/1000\n",
      "166/166 [==============================] - 0s 222us/step - loss: 0.0015\n",
      "Epoch 79/1000\n",
      "166/166 [==============================] - 0s 226us/step - loss: 0.0015\n",
      "Epoch 80/1000\n",
      "166/166 [==============================] - 0s 221us/step - loss: 0.0015\n",
      "Epoch 81/1000\n",
      "166/166 [==============================] - 0s 224us/step - loss: 0.0015\n",
      "Epoch 82/1000\n",
      "166/166 [==============================] - 0s 221us/step - loss: 0.0015\n",
      "Epoch 83/1000\n",
      "166/166 [==============================] - 0s 233us/step - loss: 0.0014\n",
      "Epoch 84/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0015\n",
      "Epoch 85/1000\n",
      "166/166 [==============================] - 0s 224us/step - loss: 0.0014\n",
      "Epoch 86/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0015\n",
      "Epoch 87/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0015\n",
      "Epoch 88/1000\n",
      "166/166 [==============================] - 0s 226us/step - loss: 0.0014\n",
      "Epoch 89/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0015\n",
      "Epoch 90/1000\n",
      "166/166 [==============================] - 0s 221us/step - loss: 0.0015\n",
      "Epoch 91/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0014\n",
      "Epoch 92/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0015\n",
      "Epoch 93/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0014\n",
      "Epoch 94/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0014\n",
      "Epoch 95/1000\n",
      "166/166 [==============================] - 0s 221us/step - loss: 0.0014\n",
      "Epoch 96/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 0s 209us/step - loss: 0.0014\n",
      "Epoch 97/1000\n",
      "166/166 [==============================] - 0s 202us/step - loss: 0.0014\n",
      "Epoch 98/1000\n",
      "166/166 [==============================] - 0s 204us/step - loss: 0.0014\n",
      "Epoch 99/1000\n",
      "166/166 [==============================] - 0s 236us/step - loss: 0.0014\n",
      "Epoch 100/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0014\n",
      "Epoch 101/1000\n",
      "166/166 [==============================] - 0s 221us/step - loss: 0.0014\n",
      "Epoch 102/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0014\n",
      "Epoch 103/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0014\n",
      "Epoch 104/1000\n",
      "166/166 [==============================] - 0s 222us/step - loss: 0.0014\n",
      "Epoch 105/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0014\n",
      "Epoch 106/1000\n",
      "166/166 [==============================] - 0s 223us/step - loss: 0.0014\n",
      "Epoch 107/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0014\n",
      "Epoch 108/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0014\n",
      "Epoch 109/1000\n",
      "166/166 [==============================] - 0s 221us/step - loss: 0.0014\n",
      "Epoch 110/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0014\n",
      "Epoch 111/1000\n",
      "166/166 [==============================] - 0s 233us/step - loss: 0.0014\n",
      "Epoch 112/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0014\n",
      "Epoch 113/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0014\n",
      "Epoch 114/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0014\n",
      "Epoch 115/1000\n",
      "166/166 [==============================] - 0s 224us/step - loss: 0.0014\n",
      "Epoch 116/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0014\n",
      "Epoch 117/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0014\n",
      "Epoch 118/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0014\n",
      "Epoch 119/1000\n",
      "166/166 [==============================] - 0s 220us/step - loss: 0.0014\n",
      "Epoch 120/1000\n",
      "166/166 [==============================] - 0s 223us/step - loss: 0.0013\n",
      "Epoch 121/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0013\n",
      "Epoch 122/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0014\n",
      "Epoch 123/1000\n",
      "166/166 [==============================] - 0s 223us/step - loss: 0.0013\n",
      "Epoch 124/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0014\n",
      "Epoch 125/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0014\n",
      "Epoch 126/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0014\n",
      "Epoch 127/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0013\n",
      "Epoch 128/1000\n",
      "166/166 [==============================] - 0s 229us/step - loss: 0.0014\n",
      "Epoch 129/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0014\n",
      "Epoch 130/1000\n",
      "166/166 [==============================] - 0s 229us/step - loss: 0.0013\n",
      "Epoch 131/1000\n",
      "166/166 [==============================] - 0s 221us/step - loss: 0.0014\n",
      "Epoch 132/1000\n",
      "166/166 [==============================] - 0s 226us/step - loss: 0.0013\n",
      "Epoch 133/1000\n",
      "166/166 [==============================] - 0s 223us/step - loss: 0.0013\n",
      "Epoch 134/1000\n",
      "166/166 [==============================] - 0s 223us/step - loss: 0.0013\n",
      "Epoch 135/1000\n",
      "166/166 [==============================] - 0s 230us/step - loss: 0.0013\n",
      "Epoch 136/1000\n",
      "166/166 [==============================] - 0s 224us/step - loss: 0.0013\n",
      "Epoch 137/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0013\n",
      "Epoch 138/1000\n",
      "166/166 [==============================] - 0s 228us/step - loss: 0.0013\n",
      "Epoch 139/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0013\n",
      "Epoch 140/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0013\n",
      "Epoch 141/1000\n",
      "166/166 [==============================] - 0s 241us/step - loss: 0.0014\n",
      "Epoch 142/1000\n",
      "166/166 [==============================] - 0s 222us/step - loss: 0.0013\n",
      "Epoch 143/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0013\n",
      "Epoch 144/1000\n",
      "166/166 [==============================] - 0s 223us/step - loss: 0.0013\n",
      "Epoch 145/1000\n",
      "166/166 [==============================] - 0s 221us/step - loss: 0.0013\n",
      "Epoch 146/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0013\n",
      "Epoch 147/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0013\n",
      "Epoch 148/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0013\n",
      "Epoch 149/1000\n",
      "166/166 [==============================] - 0s 221us/step - loss: 0.0013\n",
      "Epoch 150/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0013\n",
      "Epoch 151/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0013\n",
      "Epoch 152/1000\n",
      "166/166 [==============================] - 0s 222us/step - loss: 0.0013\n",
      "Epoch 153/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0013\n",
      "Epoch 154/1000\n",
      "166/166 [==============================] - 0s 223us/step - loss: 0.0013\n",
      "Epoch 155/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0013\n",
      "Epoch 156/1000\n",
      "166/166 [==============================] - 0s 227us/step - loss: 0.0013\n",
      "Epoch 157/1000\n",
      "166/166 [==============================] - 0s 222us/step - loss: 0.0013\n",
      "Epoch 158/1000\n",
      "166/166 [==============================] - 0s 227us/step - loss: 0.0013\n",
      "Epoch 159/1000\n",
      "166/166 [==============================] - 0s 229us/step - loss: 0.0013\n",
      "Epoch 160/1000\n",
      "166/166 [==============================] - 0s 220us/step - loss: 0.0013\n",
      "Epoch 161/1000\n",
      "166/166 [==============================] - 0s 226us/step - loss: 0.0013\n",
      "Epoch 162/1000\n",
      "166/166 [==============================] - 0s 221us/step - loss: 0.0013\n",
      "Epoch 163/1000\n",
      "166/166 [==============================] - 0s 222us/step - loss: 0.0013\n",
      "Epoch 164/1000\n",
      "166/166 [==============================] - 0s 224us/step - loss: 0.0013\n",
      "Epoch 165/1000\n",
      "166/166 [==============================] - 0s 220us/step - loss: 0.0013\n",
      "Epoch 166/1000\n",
      "166/166 [==============================] - 0s 225us/step - loss: 0.0013\n",
      "Epoch 167/1000\n",
      "166/166 [==============================] - 0s 225us/step - loss: 0.0013\n",
      "Epoch 168/1000\n",
      "166/166 [==============================] - 0s 225us/step - loss: 0.0013\n",
      "Epoch 169/1000\n",
      "166/166 [==============================] - 0s 220us/step - loss: 0.0013\n",
      "Epoch 170/1000\n",
      "166/166 [==============================] - 0s 221us/step - loss: 0.0013\n",
      "Epoch 171/1000\n",
      "166/166 [==============================] - 0s 229us/step - loss: 0.0013\n",
      "Epoch 172/1000\n",
      "166/166 [==============================] - 0s 223us/step - loss: 0.0013\n",
      "Epoch 173/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0012\n",
      "Epoch 174/1000\n",
      "166/166 [==============================] - 0s 223us/step - loss: 0.0012\n",
      "Epoch 175/1000\n",
      "166/166 [==============================] - 0s 221us/step - loss: 0.0012\n",
      "Epoch 176/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0013\n",
      "Epoch 177/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0012\n",
      "Epoch 178/1000\n",
      "166/166 [==============================] - 0s 228us/step - loss: 0.0013\n",
      "Epoch 179/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0013\n",
      "Epoch 180/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0012\n",
      "Epoch 181/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0013\n",
      "Epoch 182/1000\n",
      "166/166 [==============================] - 0s 225us/step - loss: 0.0012\n",
      "Epoch 183/1000\n",
      "166/166 [==============================] - 0s 222us/step - loss: 0.0013\n",
      "Epoch 184/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0013\n",
      "Epoch 185/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0012\n",
      "Epoch 186/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0012\n",
      "Epoch 187/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0012\n",
      "Epoch 188/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0012\n",
      "Epoch 189/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0013\n",
      "Epoch 190/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 0s 213us/step - loss: 0.0012\n",
      "Epoch 191/1000\n",
      "166/166 [==============================] - 0s 183us/step - loss: 0.0012\n",
      "Epoch 192/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0012\n",
      "Epoch 193/1000\n",
      "166/166 [==============================] - 0s 184us/step - loss: 0.0013\n",
      "Epoch 194/1000\n",
      "166/166 [==============================] - 0s 201us/step - loss: 0.0012\n",
      "Epoch 195/1000\n",
      "166/166 [==============================] - 0s 192us/step - loss: 0.0013\n",
      "Epoch 196/1000\n",
      "166/166 [==============================] - 0s 193us/step - loss: 0.0012\n",
      "Epoch 197/1000\n",
      "166/166 [==============================] - 0s 198us/step - loss: 0.0012\n",
      "Epoch 198/1000\n",
      "166/166 [==============================] - 0s 190us/step - loss: 0.0012\n",
      "Epoch 199/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0012\n",
      "Epoch 200/1000\n",
      "166/166 [==============================] - 0s 202us/step - loss: 0.0012\n",
      "Epoch 201/1000\n",
      "166/166 [==============================] - 0s 198us/step - loss: 0.0012\n",
      "Epoch 202/1000\n",
      "166/166 [==============================] - 0s 222us/step - loss: 0.0012\n",
      "Epoch 203/1000\n",
      "166/166 [==============================] - 0s 228us/step - loss: 0.0012\n",
      "Epoch 204/1000\n",
      "166/166 [==============================] - 0s 220us/step - loss: 0.0012\n",
      "Epoch 205/1000\n",
      "166/166 [==============================] - 0s 220us/step - loss: 0.0012\n",
      "Epoch 206/1000\n",
      "166/166 [==============================] - 0s 231us/step - loss: 0.0012\n",
      "Epoch 207/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0012\n",
      "Epoch 208/1000\n",
      "166/166 [==============================] - 0s 228us/step - loss: 0.0012\n",
      "Epoch 209/1000\n",
      "166/166 [==============================] - 0s 236us/step - loss: 0.0012\n",
      "Epoch 210/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0012\n",
      "Epoch 211/1000\n",
      "166/166 [==============================] - 0s 202us/step - loss: 0.0012\n",
      "Epoch 212/1000\n",
      "166/166 [==============================] - 0s 237us/step - loss: 0.0012\n",
      "Epoch 213/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0012\n",
      "Epoch 214/1000\n",
      "166/166 [==============================] - 0s 182us/step - loss: 0.0013\n",
      "Epoch 215/1000\n",
      "166/166 [==============================] - 0s 185us/step - loss: 0.0012\n",
      "Epoch 216/1000\n",
      "166/166 [==============================] - 0s 191us/step - loss: 0.0012\n",
      "Epoch 217/1000\n",
      "166/166 [==============================] - 0s 194us/step - loss: 0.0012\n",
      "Epoch 218/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0012\n",
      "Epoch 219/1000\n",
      "166/166 [==============================] - 0s 189us/step - loss: 0.0012\n",
      "Epoch 220/1000\n",
      "166/166 [==============================] - 0s 196us/step - loss: 0.0012\n",
      "Epoch 221/1000\n",
      "166/166 [==============================] - 0s 198us/step - loss: 0.0012\n",
      "Epoch 222/1000\n",
      "166/166 [==============================] - 0s 199us/step - loss: 0.0012\n",
      "Epoch 223/1000\n",
      "166/166 [==============================] - 0s 187us/step - loss: 0.0012\n",
      "Epoch 224/1000\n",
      "166/166 [==============================] - 0s 204us/step - loss: 0.0012\n",
      "Epoch 225/1000\n",
      "166/166 [==============================] - 0s 188us/step - loss: 0.0012\n",
      "Epoch 226/1000\n",
      "166/166 [==============================] - 0s 191us/step - loss: 0.0012\n",
      "Epoch 227/1000\n",
      "166/166 [==============================] - 0s 185us/step - loss: 0.0012\n",
      "Epoch 228/1000\n",
      "166/166 [==============================] - 0s 191us/step - loss: 0.0012\n",
      "Epoch 229/1000\n",
      "166/166 [==============================] - 0s 202us/step - loss: 0.0012\n",
      "Epoch 230/1000\n",
      "166/166 [==============================] - 0s 196us/step - loss: 0.0012\n",
      "Epoch 231/1000\n",
      "166/166 [==============================] - 0s 184us/step - loss: 0.0012\n",
      "Epoch 232/1000\n",
      "166/166 [==============================] - 0s 185us/step - loss: 0.0012\n",
      "Epoch 233/1000\n",
      "166/166 [==============================] - 0s 187us/step - loss: 0.0012\n",
      "Epoch 234/1000\n",
      "166/166 [==============================] - 0s 192us/step - loss: 0.0012\n",
      "Epoch 235/1000\n",
      "166/166 [==============================] - 0s 192us/step - loss: 0.0011\n",
      "Epoch 236/1000\n",
      "166/166 [==============================] - 0s 186us/step - loss: 0.0012\n",
      "Epoch 237/1000\n",
      "166/166 [==============================] - 0s 194us/step - loss: 0.0012\n",
      "Epoch 238/1000\n",
      "166/166 [==============================] - 0s 194us/step - loss: 0.0012\n",
      "Epoch 239/1000\n",
      "166/166 [==============================] - 0s 188us/step - loss: 0.0012\n",
      "Epoch 240/1000\n",
      "166/166 [==============================] - 0s 184us/step - loss: 0.0012\n",
      "Epoch 241/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0012\n",
      "Epoch 242/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0012\n",
      "Epoch 243/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0012\n",
      "Epoch 244/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0012\n",
      "Epoch 245/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0012\n",
      "Epoch 246/1000\n",
      "166/166 [==============================] - 0s 203us/step - loss: 0.0012\n",
      "Epoch 247/1000\n",
      "166/166 [==============================] - 0s 197us/step - loss: 0.0011\n",
      "Epoch 248/1000\n",
      "166/166 [==============================] - 0s 197us/step - loss: 0.0011\n",
      "Epoch 249/1000\n",
      "166/166 [==============================] - 0s 196us/step - loss: 0.0011\n",
      "Epoch 250/1000\n",
      "166/166 [==============================] - 0s 192us/step - loss: 0.0012\n",
      "Epoch 251/1000\n",
      "166/166 [==============================] - 0s 203us/step - loss: 0.0012\n",
      "Epoch 252/1000\n",
      "166/166 [==============================] - 0s 221us/step - loss: 0.0012\n",
      "Epoch 253/1000\n",
      "166/166 [==============================] - 0s 220us/step - loss: 0.0012\n",
      "Epoch 254/1000\n",
      "166/166 [==============================] - 0s 227us/step - loss: 0.0011\n",
      "Epoch 255/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0012\n",
      "Epoch 256/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0011\n",
      "Epoch 257/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0012\n",
      "Epoch 258/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0011\n",
      "Epoch 259/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0011\n",
      "Epoch 260/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0011\n",
      "Epoch 261/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0011\n",
      "Epoch 262/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0012\n",
      "Epoch 263/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0012\n",
      "Epoch 264/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0011\n",
      "Epoch 265/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0011\n",
      "Epoch 266/1000\n",
      "166/166 [==============================] - 0s 238us/step - loss: 0.0011\n",
      "Epoch 267/1000\n",
      "166/166 [==============================] - 0s 221us/step - loss: 0.0011\n",
      "Epoch 268/1000\n",
      "166/166 [==============================] - 0s 241us/step - loss: 0.0011\n",
      "Epoch 269/1000\n",
      "166/166 [==============================] - 0s 222us/step - loss: 0.0011\n",
      "Epoch 270/1000\n",
      "166/166 [==============================] - 0s 232us/step - loss: 0.0011\n",
      "Epoch 271/1000\n",
      "166/166 [==============================] - 0s 220us/step - loss: 0.0011\n",
      "Epoch 272/1000\n",
      "166/166 [==============================] - 0s 224us/step - loss: 0.0012\n",
      "Epoch 273/1000\n",
      "166/166 [==============================] - 0s 224us/step - loss: 0.0011\n",
      "Epoch 274/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0011\n",
      "Epoch 275/1000\n",
      "166/166 [==============================] - 0s 222us/step - loss: 0.0011\n",
      "Epoch 276/1000\n",
      "166/166 [==============================] - 0s 230us/step - loss: 0.0011\n",
      "Epoch 277/1000\n",
      "166/166 [==============================] - 0s 227us/step - loss: 0.0012\n",
      "Epoch 278/1000\n",
      "166/166 [==============================] - 0s 223us/step - loss: 0.0011\n",
      "Epoch 279/1000\n",
      "166/166 [==============================] - 0s 234us/step - loss: 0.0011\n",
      "Epoch 280/1000\n",
      "166/166 [==============================] - 0s 223us/step - loss: 0.0011\n",
      "Epoch 281/1000\n",
      "166/166 [==============================] - 0s 223us/step - loss: 0.0011\n",
      "Epoch 282/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0011\n",
      "Epoch 283/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0011\n",
      "Epoch 284/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 0s 211us/step - loss: 0.0012\n",
      "Epoch 285/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0011\n",
      "Epoch 286/1000\n",
      "166/166 [==============================] - 0s 224us/step - loss: 0.0011\n",
      "Epoch 287/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0011\n",
      "Epoch 288/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0011\n",
      "Epoch 289/1000\n",
      "166/166 [==============================] - 0s 204us/step - loss: 0.0012\n",
      "Epoch 290/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0011\n",
      "Epoch 291/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0011\n",
      "Epoch 292/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0011\n",
      "Epoch 293/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0011\n",
      "Epoch 294/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0011\n",
      "Epoch 295/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0011\n",
      "Epoch 296/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0011\n",
      "Epoch 297/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0011\n",
      "Epoch 298/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0011\n",
      "Epoch 299/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0011\n",
      "Epoch 300/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0011\n",
      "Epoch 301/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0011\n",
      "Epoch 302/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0011\n",
      "Epoch 303/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0011\n",
      "Epoch 304/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0011\n",
      "Epoch 305/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0011\n",
      "Epoch 306/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0011\n",
      "Epoch 307/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0012\n",
      "Epoch 308/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0012\n",
      "Epoch 309/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0011\n",
      "Epoch 310/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0011\n",
      "Epoch 311/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0011\n",
      "Epoch 312/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0011\n",
      "Epoch 313/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0011\n",
      "Epoch 314/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0012\n",
      "Epoch 315/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0011\n",
      "Epoch 316/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0011\n",
      "Epoch 317/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0011\n",
      "Epoch 318/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0011\n",
      "Epoch 319/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0011\n",
      "Epoch 320/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0011\n",
      "Epoch 321/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0011\n",
      "Epoch 322/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0011\n",
      "Epoch 323/1000\n",
      "166/166 [==============================] - 0s 220us/step - loss: 0.0011\n",
      "Epoch 324/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0011\n",
      "Epoch 325/1000\n",
      "166/166 [==============================] - 0s 205us/step - loss: 0.0011\n",
      "Epoch 326/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0011\n",
      "Epoch 327/1000\n",
      "166/166 [==============================] - 0s 205us/step - loss: 0.0011\n",
      "Epoch 328/1000\n",
      "166/166 [==============================] - 0s 198us/step - loss: 0.0011\n",
      "Epoch 329/1000\n",
      "166/166 [==============================] - 0s 182us/step - loss: 0.0011\n",
      "Epoch 330/1000\n",
      "166/166 [==============================] - 0s 185us/step - loss: 0.0011\n",
      "Epoch 331/1000\n",
      "166/166 [==============================] - 0s 187us/step - loss: 0.0012\n",
      "Epoch 332/1000\n",
      "166/166 [==============================] - 0s 194us/step - loss: 0.0011\n",
      "Epoch 333/1000\n",
      "166/166 [==============================] - 0s 188us/step - loss: 0.0011\n",
      "Epoch 334/1000\n",
      "166/166 [==============================] - 0s 188us/step - loss: 0.0011\n",
      "Epoch 335/1000\n",
      "166/166 [==============================] - 0s 184us/step - loss: 0.0011\n",
      "Epoch 336/1000\n",
      "166/166 [==============================] - 0s 183us/step - loss: 0.0011\n",
      "Epoch 337/1000\n",
      "166/166 [==============================] - 0s 188us/step - loss: 0.0011\n",
      "Epoch 338/1000\n",
      "166/166 [==============================] - 0s 181us/step - loss: 0.0012\n",
      "Epoch 339/1000\n",
      "166/166 [==============================] - 0s 187us/step - loss: 0.0011\n",
      "Epoch 340/1000\n",
      "166/166 [==============================] - 0s 186us/step - loss: 0.0011\n",
      "Epoch 341/1000\n",
      "166/166 [==============================] - 0s 189us/step - loss: 0.0011\n",
      "Epoch 342/1000\n",
      "166/166 [==============================] - 0s 189us/step - loss: 0.0011\n",
      "Epoch 343/1000\n",
      "166/166 [==============================] - 0s 182us/step - loss: 0.0011\n",
      "Epoch 344/1000\n",
      "166/166 [==============================] - 0s 174us/step - loss: 0.0011\n",
      "Epoch 345/1000\n",
      "166/166 [==============================] - 0s 197us/step - loss: 0.0011\n",
      "Epoch 346/1000\n",
      "166/166 [==============================] - 0s 190us/step - loss: 0.0011\n",
      "Epoch 347/1000\n",
      "166/166 [==============================] - 0s 201us/step - loss: 0.0011\n",
      "Epoch 348/1000\n",
      "166/166 [==============================] - 0s 188us/step - loss: 0.0011\n",
      "Epoch 349/1000\n",
      "166/166 [==============================] - 0s 189us/step - loss: 0.0011\n",
      "Epoch 350/1000\n",
      "166/166 [==============================] - 0s 194us/step - loss: 0.0011\n",
      "Epoch 351/1000\n",
      "166/166 [==============================] - 0s 187us/step - loss: 0.0011\n",
      "Epoch 352/1000\n",
      "166/166 [==============================] - 0s 182us/step - loss: 0.0011\n",
      "Epoch 353/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0011\n",
      "Epoch 354/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0011\n",
      "Epoch 355/1000\n",
      "166/166 [==============================] - 0s 199us/step - loss: 0.0011\n",
      "Epoch 356/1000\n",
      "166/166 [==============================] - 0s 197us/step - loss: 0.0011\n",
      "Epoch 357/1000\n",
      "166/166 [==============================] - 0s 194us/step - loss: 0.0011\n",
      "Epoch 358/1000\n",
      "166/166 [==============================] - 0s 196us/step - loss: 0.0011\n",
      "Epoch 359/1000\n",
      "166/166 [==============================] - 0s 196us/step - loss: 0.0011\n",
      "Epoch 360/1000\n",
      "166/166 [==============================] - 0s 199us/step - loss: 0.0011\n",
      "Epoch 361/1000\n",
      "166/166 [==============================] - 0s 199us/step - loss: 0.0011\n",
      "Epoch 362/1000\n",
      "166/166 [==============================] - 0s 197us/step - loss: 0.0011\n",
      "Epoch 363/1000\n",
      "166/166 [==============================] - 0s 204us/step - loss: 0.0011\n",
      "Epoch 364/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0011\n",
      "Epoch 365/1000\n",
      "166/166 [==============================] - 0s 200us/step - loss: 0.0011\n",
      "Epoch 366/1000\n",
      "166/166 [==============================] - 0s 195us/step - loss: 0.0011\n",
      "Epoch 367/1000\n",
      "166/166 [==============================] - 0s 200us/step - loss: 0.0011\n",
      "Epoch 368/1000\n",
      "166/166 [==============================] - 0s 205us/step - loss: 0.0011\n",
      "Epoch 369/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0011\n",
      "Epoch 370/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0011\n",
      "Epoch 371/1000\n",
      "166/166 [==============================] - 0s 203us/step - loss: 0.0011\n",
      "Epoch 372/1000\n",
      "166/166 [==============================] - 0s 189us/step - loss: 0.0011\n",
      "Epoch 373/1000\n",
      "166/166 [==============================] - 0s 171us/step - loss: 0.0011\n",
      "Epoch 374/1000\n",
      "166/166 [==============================] - 0s 182us/step - loss: 0.0011\n",
      "Epoch 375/1000\n",
      "166/166 [==============================] - 0s 181us/step - loss: 0.0011\n",
      "Epoch 376/1000\n",
      "166/166 [==============================] - 0s 189us/step - loss: 0.0011\n",
      "Epoch 377/1000\n",
      "166/166 [==============================] - 0s 185us/step - loss: 0.0011\n",
      "Epoch 378/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 0s 177us/step - loss: 0.0011\n",
      "Epoch 379/1000\n",
      "166/166 [==============================] - 0s 176us/step - loss: 0.0011\n",
      "Epoch 380/1000\n",
      "166/166 [==============================] - 0s 198us/step - loss: 0.0011\n",
      "Epoch 381/1000\n",
      "166/166 [==============================] - 0s 200us/step - loss: 0.0011\n",
      "Epoch 382/1000\n",
      "166/166 [==============================] - 0s 197us/step - loss: 0.0011\n",
      "Epoch 383/1000\n",
      "166/166 [==============================] - 0s 197us/step - loss: 0.0011\n",
      "Epoch 384/1000\n",
      "166/166 [==============================] - 0s 204us/step - loss: 0.0011\n",
      "Epoch 385/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0011\n",
      "Epoch 386/1000\n",
      "166/166 [==============================] - 0s 193us/step - loss: 0.0011\n",
      "Epoch 387/1000\n",
      "166/166 [==============================] - 0s 195us/step - loss: 0.0011\n",
      "Epoch 388/1000\n",
      "166/166 [==============================] - 0s 193us/step - loss: 0.0011\n",
      "Epoch 389/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0011\n",
      "Epoch 390/1000\n",
      "166/166 [==============================] - 0s 226us/step - loss: 0.0011\n",
      "Epoch 391/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0011\n",
      "Epoch 392/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0011\n",
      "Epoch 393/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0011\n",
      "Epoch 394/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0011\n",
      "Epoch 395/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0011\n",
      "Epoch 396/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0011\n",
      "Epoch 397/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0011\n",
      "Epoch 398/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0011\n",
      "Epoch 399/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0012\n",
      "Epoch 400/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0011\n",
      "Epoch 401/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0011\n",
      "Epoch 402/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0011\n",
      "Epoch 403/1000\n",
      "166/166 [==============================] - 0s 203us/step - loss: 0.0011\n",
      "Epoch 404/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0011\n",
      "Epoch 405/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0011\n",
      "Epoch 406/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0011\n",
      "Epoch 407/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0011\n",
      "Epoch 408/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0011\n",
      "Epoch 409/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0011\n",
      "Epoch 410/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0011\n",
      "Epoch 411/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0011\n",
      "Epoch 412/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0011\n",
      "Epoch 413/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0011\n",
      "Epoch 414/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0011\n",
      "Epoch 415/1000\n",
      "166/166 [==============================] - 0s 220us/step - loss: 0.0011\n",
      "Epoch 416/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0011\n",
      "Epoch 417/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0011\n",
      "Epoch 418/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0011\n",
      "Epoch 419/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0011\n",
      "Epoch 420/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0011\n",
      "Epoch 421/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0011\n",
      "Epoch 422/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0011\n",
      "Epoch 423/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0011\n",
      "Epoch 424/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0011\n",
      "Epoch 425/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0011\n",
      "Epoch 426/1000\n",
      "166/166 [==============================] - 0s 224us/step - loss: 0.0011\n",
      "Epoch 427/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0011\n",
      "Epoch 428/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0011\n",
      "Epoch 429/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0011\n",
      "Epoch 430/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0010\n",
      "Epoch 431/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0010\n",
      "Epoch 432/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0010\n",
      "Epoch 433/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0011\n",
      "Epoch 434/1000\n",
      "166/166 [==============================] - 0s 220us/step - loss: 0.0011\n",
      "Epoch 435/1000\n",
      "166/166 [==============================] - 0s 204us/step - loss: 0.0011\n",
      "Epoch 436/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0011\n",
      "Epoch 437/1000\n",
      "166/166 [==============================] - 0s 220us/step - loss: 0.0011\n",
      "Epoch 438/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0011\n",
      "Epoch 439/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0011\n",
      "Epoch 440/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0010\n",
      "Epoch 441/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0010\n",
      "Epoch 442/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0011\n",
      "Epoch 443/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0011\n",
      "Epoch 444/1000\n",
      "166/166 [==============================] - 0s 223us/step - loss: 0.0011\n",
      "Epoch 445/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0011\n",
      "Epoch 446/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0010\n",
      "Epoch 447/1000\n",
      "166/166 [==============================] - 0s 222us/step - loss: 0.0010\n",
      "Epoch 448/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0011\n",
      "Epoch 449/1000\n",
      "166/166 [==============================] - 0s 223us/step - loss: 0.0011\n",
      "Epoch 450/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0011\n",
      "Epoch 451/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0010\n",
      "Epoch 452/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0011\n",
      "Epoch 453/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0011\n",
      "Epoch 454/1000\n",
      "166/166 [==============================] - 0s 201us/step - loss: 0.0011\n",
      "Epoch 455/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0011\n",
      "Epoch 456/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0010\n",
      "Epoch 457/1000\n",
      "166/166 [==============================] - 0s 223us/step - loss: 0.0010\n",
      "Epoch 458/1000\n",
      "166/166 [==============================] - 0s 200us/step - loss: 0.0011\n",
      "Epoch 459/1000\n",
      "166/166 [==============================] - 0s 225us/step - loss: 0.0010\n",
      "Epoch 460/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0011\n",
      "Epoch 461/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0011\n",
      "Epoch 462/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0011\n",
      "Epoch 463/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0011\n",
      "Epoch 464/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0010\n",
      "Epoch 465/1000\n",
      "166/166 [==============================] - 0s 203us/step - loss: 0.0011\n",
      "Epoch 466/1000\n",
      "166/166 [==============================] - 0s 205us/step - loss: 0.0011\n",
      "Epoch 467/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0010\n",
      "Epoch 468/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0011\n",
      "Epoch 469/1000\n",
      "166/166 [==============================] - 0s 179us/step - loss: 0.0011\n",
      "Epoch 470/1000\n",
      "166/166 [==============================] - 0s 177us/step - loss: 0.0011\n",
      "Epoch 471/1000\n",
      "166/166 [==============================] - 0s 182us/step - loss: 0.0011\n",
      "Epoch 472/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 0s 183us/step - loss: 0.0011\n",
      "Epoch 473/1000\n",
      "166/166 [==============================] - 0s 178us/step - loss: 0.0010\n",
      "Epoch 474/1000\n",
      "166/166 [==============================] - 0s 183us/step - loss: 0.0011\n",
      "Epoch 475/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0010\n",
      "Epoch 476/1000\n",
      "166/166 [==============================] - 0s 197us/step - loss: 0.0010\n",
      "Epoch 477/1000\n",
      "166/166 [==============================] - 0s 205us/step - loss: 0.0011\n",
      "Epoch 478/1000\n",
      "166/166 [==============================] - 0s 195us/step - loss: 0.0010\n",
      "Epoch 479/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0011\n",
      "Epoch 480/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0011\n",
      "Epoch 481/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0010\n",
      "Epoch 482/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0011\n",
      "Epoch 483/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0010\n",
      "Epoch 484/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0010\n",
      "Epoch 485/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0010\n",
      "Epoch 486/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0011\n",
      "Epoch 487/1000\n",
      "166/166 [==============================] - 0s 202us/step - loss: 0.0011\n",
      "Epoch 488/1000\n",
      "166/166 [==============================] - 0s 204us/step - loss: 0.0011\n",
      "Epoch 489/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0010\n",
      "Epoch 490/1000\n",
      "166/166 [==============================] - 0s 221us/step - loss: 0.0011\n",
      "Epoch 491/1000\n",
      "166/166 [==============================] - 0s 205us/step - loss: 0.0011\n",
      "Epoch 492/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0010\n",
      "Epoch 493/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0010\n",
      "Epoch 494/1000\n",
      "166/166 [==============================] - 0s 193us/step - loss: 0.0011\n",
      "Epoch 495/1000\n",
      "166/166 [==============================] - 0s 187us/step - loss: 0.0010\n",
      "Epoch 496/1000\n",
      "166/166 [==============================] - 0s 185us/step - loss: 0.0010\n",
      "Epoch 497/1000\n",
      "166/166 [==============================] - 0s 190us/step - loss: 0.0010\n",
      "Epoch 498/1000\n",
      "166/166 [==============================] - 0s 188us/step - loss: 0.0011\n",
      "Epoch 499/1000\n",
      "166/166 [==============================] - 0s 185us/step - loss: 0.0010\n",
      "Epoch 500/1000\n",
      "166/166 [==============================] - 0s 194us/step - loss: 0.0011\n",
      "Epoch 501/1000\n",
      "166/166 [==============================] - 0s 194us/step - loss: 0.0010\n",
      "Epoch 502/1000\n",
      "166/166 [==============================] - 0s 182us/step - loss: 0.0011\n",
      "Epoch 503/1000\n",
      "166/166 [==============================] - 0s 189us/step - loss: 0.0010\n",
      "Epoch 504/1000\n",
      "166/166 [==============================] - 0s 202us/step - loss: 0.0011\n",
      "Epoch 505/1000\n",
      "166/166 [==============================] - 0s 186us/step - loss: 0.0010\n",
      "Epoch 506/1000\n",
      "166/166 [==============================] - 0s 192us/step - loss: 0.0011\n",
      "Epoch 507/1000\n",
      "166/166 [==============================] - 0s 199us/step - loss: 0.0010\n",
      "Epoch 508/1000\n",
      "166/166 [==============================] - 0s 192us/step - loss: 0.0010\n",
      "Epoch 509/1000\n",
      "166/166 [==============================] - 0s 187us/step - loss: 0.0010\n",
      "Epoch 510/1000\n",
      "166/166 [==============================] - 0s 192us/step - loss: 0.0010\n",
      "Epoch 511/1000\n",
      "166/166 [==============================] - 0s 190us/step - loss: 0.0010\n",
      "Epoch 512/1000\n",
      "166/166 [==============================] - 0s 199us/step - loss: 0.0010\n",
      "Epoch 513/1000\n",
      "166/166 [==============================] - 0s 201us/step - loss: 0.0010\n",
      "Epoch 514/1000\n",
      "166/166 [==============================] - 0s 187us/step - loss: 0.0010\n",
      "Epoch 515/1000\n",
      "166/166 [==============================] - 0s 190us/step - loss: 0.0010\n",
      "Epoch 516/1000\n",
      "166/166 [==============================] - 0s 196us/step - loss: 0.0011\n",
      "Epoch 517/1000\n",
      "166/166 [==============================] - 0s 190us/step - loss: 0.0010\n",
      "Epoch 518/1000\n",
      "166/166 [==============================] - 0s 189us/step - loss: 0.0010\n",
      "Epoch 519/1000\n",
      "166/166 [==============================] - 0s 195us/step - loss: 0.0011\n",
      "Epoch 520/1000\n",
      "166/166 [==============================] - 0s 204us/step - loss: 0.0011\n",
      "Epoch 521/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0010\n",
      "Epoch 522/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0010\n",
      "Epoch 523/1000\n",
      "166/166 [==============================] - 0s 197us/step - loss: 0.0011\n",
      "Epoch 524/1000\n",
      "166/166 [==============================] - 0s 200us/step - loss: 0.0010\n",
      "Epoch 525/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0010\n",
      "Epoch 526/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0011\n",
      "Epoch 527/1000\n",
      "166/166 [==============================] - 0s 200us/step - loss: 0.0010\n",
      "Epoch 528/1000\n",
      "166/166 [==============================] - 0s 200us/step - loss: 0.0011\n",
      "Epoch 529/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0010\n",
      "Epoch 530/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0011\n",
      "Epoch 531/1000\n",
      "166/166 [==============================] - 0s 221us/step - loss: 0.0011\n",
      "Epoch 532/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0011\n",
      "Epoch 533/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0010\n",
      "Epoch 534/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0010\n",
      "Epoch 535/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0011\n",
      "Epoch 536/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0010\n",
      "Epoch 537/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0010\n",
      "Epoch 538/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0011\n",
      "Epoch 539/1000\n",
      "166/166 [==============================] - 0s 203us/step - loss: 0.0010\n",
      "Epoch 540/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0011\n",
      "Epoch 541/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0011\n",
      "Epoch 542/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0010\n",
      "Epoch 543/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0010\n",
      "Epoch 544/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0010\n",
      "Epoch 545/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0010\n",
      "Epoch 546/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0010\n",
      "Epoch 547/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0010\n",
      "Epoch 548/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0011\n",
      "Epoch 549/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0010\n",
      "Epoch 550/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0010\n",
      "Epoch 551/1000\n",
      "166/166 [==============================] - 0s 195us/step - loss: 0.0010\n",
      "Epoch 552/1000\n",
      "166/166 [==============================] - 0s 176us/step - loss: 0.0011\n",
      "Epoch 553/1000\n",
      "166/166 [==============================] - 0s 181us/step - loss: 0.0011\n",
      "Epoch 554/1000\n",
      "166/166 [==============================] - 0s 178us/step - loss: 0.0010\n",
      "Epoch 555/1000\n",
      "166/166 [==============================] - 0s 179us/step - loss: 0.0010\n",
      "Epoch 556/1000\n",
      "166/166 [==============================] - 0s 179us/step - loss: 0.0010\n",
      "Epoch 557/1000\n",
      "166/166 [==============================] - 0s 182us/step - loss: 0.0010\n",
      "Epoch 558/1000\n",
      "166/166 [==============================] - 0s 189us/step - loss: 0.0011\n",
      "Epoch 559/1000\n",
      "166/166 [==============================] - 0s 181us/step - loss: 0.0011\n",
      "Epoch 560/1000\n",
      "166/166 [==============================] - 0s 180us/step - loss: 0.0010\n",
      "Epoch 561/1000\n",
      "166/166 [==============================] - 0s 174us/step - loss: 0.0010\n",
      "Epoch 562/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0011\n",
      "Epoch 563/1000\n",
      "166/166 [==============================] - 0s 204us/step - loss: 0.0011\n",
      "Epoch 564/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0010\n",
      "Epoch 565/1000\n",
      "166/166 [==============================] - 0s 200us/step - loss: 0.0010\n",
      "Epoch 566/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 0s 195us/step - loss: 0.0010\n",
      "Epoch 567/1000\n",
      "166/166 [==============================] - 0s 188us/step - loss: 0.0010\n",
      "Epoch 568/1000\n",
      "166/166 [==============================] - 0s 192us/step - loss: 0.0010\n",
      "Epoch 569/1000\n",
      "166/166 [==============================] - 0s 220us/step - loss: 0.0010\n",
      "Epoch 570/1000\n",
      "166/166 [==============================] - 0s 222us/step - loss: 0.0010\n",
      "Epoch 571/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0010\n",
      "Epoch 572/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0010\n",
      "Epoch 573/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0011\n",
      "Epoch 574/1000\n",
      "166/166 [==============================] - 0s 205us/step - loss: 0.0010\n",
      "Epoch 575/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0011\n",
      "Epoch 576/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0010\n",
      "Epoch 577/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0010\n",
      "Epoch 578/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0011\n",
      "Epoch 579/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0010\n",
      "Epoch 580/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0011\n",
      "Epoch 581/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0010\n",
      "Epoch 582/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0011\n",
      "Epoch 583/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0010\n",
      "Epoch 584/1000\n",
      "166/166 [==============================] - 0s 205us/step - loss: 0.0010\n",
      "Epoch 585/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0010\n",
      "Epoch 586/1000\n",
      "166/166 [==============================] - 0s 221us/step - loss: 0.0010\n",
      "Epoch 587/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0011\n",
      "Epoch 588/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0011\n",
      "Epoch 589/1000\n",
      "166/166 [==============================] - 0s 227us/step - loss: 0.0010\n",
      "Epoch 590/1000\n",
      "166/166 [==============================] - 0s 223us/step - loss: 0.0010\n",
      "Epoch 591/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0010\n",
      "Epoch 592/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0010\n",
      "Epoch 593/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0010\n",
      "Epoch 594/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0010\n",
      "Epoch 595/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0010\n",
      "Epoch 596/1000\n",
      "166/166 [==============================] - 0s 191us/step - loss: 0.0010\n",
      "Epoch 597/1000\n",
      "166/166 [==============================] - 0s 187us/step - loss: 0.0010\n",
      "Epoch 598/1000\n",
      "166/166 [==============================] - 0s 186us/step - loss: 0.0010\n",
      "Epoch 599/1000\n",
      "166/166 [==============================] - 0s 191us/step - loss: 0.0010\n",
      "Epoch 600/1000\n",
      "166/166 [==============================] - 0s 182us/step - loss: 0.0011\n",
      "Epoch 601/1000\n",
      "166/166 [==============================] - 0s 192us/step - loss: 0.0010\n",
      "Epoch 602/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0010\n",
      "Epoch 603/1000\n",
      "166/166 [==============================] - 0s 196us/step - loss: 0.0010\n",
      "Epoch 604/1000\n",
      "166/166 [==============================] - 0s 222us/step - loss: 0.0011\n",
      "Epoch 605/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0010\n",
      "Epoch 606/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0010\n",
      "Epoch 607/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0011\n",
      "Epoch 608/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0010\n",
      "Epoch 609/1000\n",
      "166/166 [==============================] - 0s 199us/step - loss: 0.0010\n",
      "Epoch 610/1000\n",
      "166/166 [==============================] - 0s 197us/step - loss: 0.0010\n",
      "Epoch 611/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0011\n",
      "Epoch 612/1000\n",
      "166/166 [==============================] - 0s 223us/step - loss: 0.0011\n",
      "Epoch 613/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0010\n",
      "Epoch 614/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0010\n",
      "Epoch 615/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0010\n",
      "Epoch 616/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0010\n",
      "Epoch 617/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0011\n",
      "Epoch 618/1000\n",
      "166/166 [==============================] - 0s 223us/step - loss: 0.0010\n",
      "Epoch 619/1000\n",
      "166/166 [==============================] - 0s 193us/step - loss: 0.0010\n",
      "Epoch 620/1000\n",
      "166/166 [==============================] - 0s 179us/step - loss: 0.0011\n",
      "Epoch 621/1000\n",
      "166/166 [==============================] - 0s 180us/step - loss: 0.0010\n",
      "Epoch 622/1000\n",
      "166/166 [==============================] - 0s 181us/step - loss: 0.0010\n",
      "Epoch 623/1000\n",
      "166/166 [==============================] - 0s 188us/step - loss: 0.0010\n",
      "Epoch 624/1000\n",
      "166/166 [==============================] - 0s 185us/step - loss: 0.0010\n",
      "Epoch 625/1000\n",
      "166/166 [==============================] - 0s 186us/step - loss: 0.0011\n",
      "Epoch 626/1000\n",
      "166/166 [==============================] - 0s 177us/step - loss: 0.0010\n",
      "Epoch 627/1000\n",
      "166/166 [==============================] - 0s 182us/step - loss: 0.0010\n",
      "Epoch 628/1000\n",
      "166/166 [==============================] - 0s 175us/step - loss: 0.0011\n",
      "Epoch 629/1000\n",
      "166/166 [==============================] - 0s 189us/step - loss: 0.0011\n",
      "Epoch 630/1000\n",
      "166/166 [==============================] - 0s 195us/step - loss: 0.0010\n",
      "Epoch 631/1000\n",
      "166/166 [==============================] - 0s 197us/step - loss: 0.0010\n",
      "Epoch 632/1000\n",
      "166/166 [==============================] - 0s 202us/step - loss: 0.0010\n",
      "Epoch 633/1000\n",
      "166/166 [==============================] - 0s 198us/step - loss: 0.0010\n",
      "Epoch 634/1000\n",
      "166/166 [==============================] - 0s 197us/step - loss: 0.0010\n",
      "Epoch 635/1000\n",
      "166/166 [==============================] - 0s 192us/step - loss: 0.0010\n",
      "Epoch 636/1000\n",
      "166/166 [==============================] - 0s 195us/step - loss: 0.0010\n",
      "Epoch 637/1000\n",
      "166/166 [==============================] - 0s 189us/step - loss: 0.0010\n",
      "Epoch 638/1000\n",
      "166/166 [==============================] - 0s 183us/step - loss: 0.0010\n",
      "Epoch 639/1000\n",
      "166/166 [==============================] - 0s 177us/step - loss: 0.0010\n",
      "Epoch 640/1000\n",
      "166/166 [==============================] - 0s 184us/step - loss: 0.0010\n",
      "Epoch 641/1000\n",
      "166/166 [==============================] - 0s 179us/step - loss: 0.0011\n",
      "Epoch 642/1000\n",
      "166/166 [==============================] - 0s 196us/step - loss: 0.0010\n",
      "Epoch 643/1000\n",
      "166/166 [==============================] - 0s 197us/step - loss: 0.0010\n",
      "Epoch 644/1000\n",
      "166/166 [==============================] - 0s 189us/step - loss: 0.0010\n",
      "Epoch 645/1000\n",
      "166/166 [==============================] - 0s 177us/step - loss: 0.0010\n",
      "Epoch 646/1000\n",
      "166/166 [==============================] - 0s 187us/step - loss: 0.0010\n",
      "Epoch 647/1000\n",
      "166/166 [==============================] - 0s 188us/step - loss: 0.0010\n",
      "Epoch 648/1000\n",
      "166/166 [==============================] - 0s 197us/step - loss: 0.0010\n",
      "Epoch 649/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0010\n",
      "Epoch 650/1000\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.001 - 0s 198us/step - loss: 0.0011\n",
      "Epoch 651/1000\n",
      "166/166 [==============================] - 0s 202us/step - loss: 0.0011\n",
      "Epoch 652/1000\n",
      "166/166 [==============================] - 0s 189us/step - loss: 0.0010\n",
      "Epoch 653/1000\n",
      "166/166 [==============================] - 0s 195us/step - loss: 0.0010\n",
      "Epoch 654/1000\n",
      "166/166 [==============================] - 0s 204us/step - loss: 0.0010\n",
      "Epoch 655/1000\n",
      "166/166 [==============================] - 0s 225us/step - loss: 0.0010\n",
      "Epoch 656/1000\n",
      "166/166 [==============================] - 0s 220us/step - loss: 0.0010\n",
      "Epoch 657/1000\n",
      "166/166 [==============================] - 0s 222us/step - loss: 0.0010\n",
      "Epoch 658/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0010\n",
      "Epoch 659/1000\n",
      "166/166 [==============================] - 0s 223us/step - loss: 0.0010\n",
      "Epoch 660/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 0s 221us/step - loss: 0.0010\n",
      "Epoch 661/1000\n",
      "166/166 [==============================] - 0s 224us/step - loss: 0.0011\n",
      "Epoch 662/1000\n",
      "166/166 [==============================] - 0s 221us/step - loss: 0.0010\n",
      "Epoch 663/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0010\n",
      "Epoch 664/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0010\n",
      "Epoch 665/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0010\n",
      "Epoch 666/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0010\n",
      "Epoch 667/1000\n",
      "166/166 [==============================] - 0s 201us/step - loss: 0.0010\n",
      "Epoch 668/1000\n",
      "166/166 [==============================] - 0s 205us/step - loss: 0.0010\n",
      "Epoch 669/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0010\n",
      "Epoch 670/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0011\n",
      "Epoch 671/1000\n",
      "166/166 [==============================] - 0s 202us/step - loss: 0.0011\n",
      "Epoch 672/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0010\n",
      "Epoch 673/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0010\n",
      "Epoch 674/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0010\n",
      "Epoch 675/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0010\n",
      "Epoch 676/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0010\n",
      "Epoch 677/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0010\n",
      "Epoch 678/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0010\n",
      "Epoch 679/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0010\n",
      "Epoch 680/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0010\n",
      "Epoch 681/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0011\n",
      "Epoch 682/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0010\n",
      "Epoch 683/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0010\n",
      "Epoch 684/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0010\n",
      "Epoch 685/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0010\n",
      "Epoch 686/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0010\n",
      "Epoch 687/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0010\n",
      "Epoch 688/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0010\n",
      "Epoch 689/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0010\n",
      "Epoch 690/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0010\n",
      "Epoch 691/1000\n",
      "166/166 [==============================] - 0s 205us/step - loss: 0.0010\n",
      "Epoch 692/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0010\n",
      "Epoch 693/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0010\n",
      "Epoch 694/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0010\n",
      "Epoch 695/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0010\n",
      "Epoch 696/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0010\n",
      "Epoch 697/1000\n",
      "166/166 [==============================] - 0s 205us/step - loss: 0.0010\n",
      "Epoch 698/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0010\n",
      "Epoch 699/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0010\n",
      "Epoch 700/1000\n",
      "166/166 [==============================] - 0s 222us/step - loss: 0.0010\n",
      "Epoch 701/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0010\n",
      "Epoch 702/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0010\n",
      "Epoch 703/1000\n",
      "166/166 [==============================] - 0s 226us/step - loss: 0.0010\n",
      "Epoch 704/1000\n",
      "166/166 [==============================] - 0s 222us/step - loss: 0.0011\n",
      "Epoch 705/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0010\n",
      "Epoch 706/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0010\n",
      "Epoch 707/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0010\n",
      "Epoch 708/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0010\n",
      "Epoch 709/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0010\n",
      "Epoch 710/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0010\n",
      "Epoch 711/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0010\n",
      "Epoch 712/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0010\n",
      "Epoch 713/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0010\n",
      "Epoch 714/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0010\n",
      "Epoch 715/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0010\n",
      "Epoch 716/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0010\n",
      "Epoch 717/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0010\n",
      "Epoch 718/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0010\n",
      "Epoch 719/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0010\n",
      "Epoch 720/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0010\n",
      "Epoch 721/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0010\n",
      "Epoch 722/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0010\n",
      "Epoch 723/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0010\n",
      "Epoch 724/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0010\n",
      "Epoch 725/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0010\n",
      "Epoch 726/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0010\n",
      "Epoch 727/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0010\n",
      "Epoch 728/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0010\n",
      "Epoch 729/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0010\n",
      "Epoch 730/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0010\n",
      "Epoch 731/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0010\n",
      "Epoch 732/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0010\n",
      "Epoch 733/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0010\n",
      "Epoch 734/1000\n",
      "166/166 [==============================] - 0s 220us/step - loss: 0.0010\n",
      "Epoch 735/1000\n",
      "166/166 [==============================] - 0s 204us/step - loss: 0.0010\n",
      "Epoch 736/1000\n",
      "166/166 [==============================] - 0s 176us/step - loss: 0.0010\n",
      "Epoch 737/1000\n",
      "166/166 [==============================] - 0s 179us/step - loss: 0.0010\n",
      "Epoch 738/1000\n",
      "166/166 [==============================] - 0s 183us/step - loss: 0.0010\n",
      "Epoch 739/1000\n",
      "166/166 [==============================] - 0s 179us/step - loss: 0.0010\n",
      "Epoch 740/1000\n",
      "166/166 [==============================] - 0s 180us/step - loss: 0.0010\n",
      "Epoch 741/1000\n",
      "166/166 [==============================] - 0s 181us/step - loss: 0.0011\n",
      "Epoch 742/1000\n",
      "166/166 [==============================] - 0s 180us/step - loss: 0.0010\n",
      "Epoch 743/1000\n",
      "166/166 [==============================] - 0s 178us/step - loss: 0.0010\n",
      "Epoch 744/1000\n",
      "166/166 [==============================] - 0s 184us/step - loss: 0.0010\n",
      "Epoch 745/1000\n",
      "166/166 [==============================] - 0s 178us/step - loss: 0.0010\n",
      "Epoch 746/1000\n",
      "166/166 [==============================] - 0s 190us/step - loss: 0.0010\n",
      "Epoch 747/1000\n",
      "166/166 [==============================] - 0s 188us/step - loss: 0.0010\n",
      "Epoch 748/1000\n",
      "166/166 [==============================] - 0s 175us/step - loss: 0.0011\n",
      "Epoch 749/1000\n",
      "166/166 [==============================] - 0s 178us/step - loss: 0.0011\n",
      "Epoch 750/1000\n",
      "166/166 [==============================] - 0s 175us/step - loss: 0.0010\n",
      "Epoch 751/1000\n",
      "166/166 [==============================] - 0s 181us/step - loss: 0.0010\n",
      "Epoch 752/1000\n",
      "166/166 [==============================] - 0s 179us/step - loss: 0.0010\n",
      "Epoch 753/1000\n",
      "166/166 [==============================] - 0s 178us/step - loss: 0.0010\n",
      "Epoch 754/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 0s 185us/step - loss: 0.0010\n",
      "Epoch 755/1000\n",
      "166/166 [==============================] - 0s 173us/step - loss: 0.0010\n",
      "Epoch 756/1000\n",
      "166/166 [==============================] - 0s 199us/step - loss: 0.0010\n",
      "Epoch 757/1000\n",
      "166/166 [==============================] - 0s 192us/step - loss: 0.0010\n",
      "Epoch 758/1000\n",
      "166/166 [==============================] - 0s 203us/step - loss: 0.0010\n",
      "Epoch 759/1000\n",
      "166/166 [==============================] - 0s 190us/step - loss: 0.0010\n",
      "Epoch 760/1000\n",
      "166/166 [==============================] - 0s 195us/step - loss: 0.0010\n",
      "Epoch 761/1000\n",
      "166/166 [==============================] - 0s 196us/step - loss: 0.0010\n",
      "Epoch 762/1000\n",
      "166/166 [==============================] - 0s 199us/step - loss: 9.9654e-04\n",
      "Epoch 763/1000\n",
      "166/166 [==============================] - 0s 198us/step - loss: 0.0010\n",
      "Epoch 764/1000\n",
      "166/166 [==============================] - 0s 193us/step - loss: 0.0010\n",
      "Epoch 765/1000\n",
      "166/166 [==============================] - 0s 203us/step - loss: 0.0010\n",
      "Epoch 766/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0010\n",
      "Epoch 767/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0010\n",
      "Epoch 768/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0010\n",
      "Epoch 769/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0010\n",
      "Epoch 770/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0010\n",
      "Epoch 771/1000\n",
      "166/166 [==============================] - 0s 204us/step - loss: 0.0010\n",
      "Epoch 772/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0010\n",
      "Epoch 773/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0010\n",
      "Epoch 774/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0010\n",
      "Epoch 775/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0010\n",
      "Epoch 776/1000\n",
      "166/166 [==============================] - 0s 227us/step - loss: 0.0010\n",
      "Epoch 777/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0010\n",
      "Epoch 778/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0010\n",
      "Epoch 779/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0011\n",
      "Epoch 780/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0010\n",
      "Epoch 781/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0010\n",
      "Epoch 782/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0010\n",
      "Epoch 783/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0010\n",
      "Epoch 784/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0010\n",
      "Epoch 785/1000\n",
      "166/166 [==============================] - 0s 220us/step - loss: 0.0010\n",
      "Epoch 786/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0010\n",
      "Epoch 787/1000\n",
      "166/166 [==============================] - 0s 201us/step - loss: 0.0010\n",
      "Epoch 788/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0010\n",
      "Epoch 789/1000\n",
      "166/166 [==============================] - 0s 224us/step - loss: 0.0010\n",
      "Epoch 790/1000\n",
      "166/166 [==============================] - 0s 222us/step - loss: 0.0010\n",
      "Epoch 791/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0010\n",
      "Epoch 792/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0010\n",
      "Epoch 793/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0010\n",
      "Epoch 794/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0010\n",
      "Epoch 795/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0010\n",
      "Epoch 796/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0010\n",
      "Epoch 797/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0010\n",
      "Epoch 798/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0010\n",
      "Epoch 799/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0010\n",
      "Epoch 800/1000\n",
      "166/166 [==============================] - 0s 220us/step - loss: 0.0010\n",
      "Epoch 801/1000\n",
      "166/166 [==============================] - 0s 220us/step - loss: 0.0010\n",
      "Epoch 802/1000\n",
      "166/166 [==============================] - 0s 221us/step - loss: 0.0010\n",
      "Epoch 803/1000\n",
      "166/166 [==============================] - 0s 224us/step - loss: 0.0011\n",
      "Epoch 804/1000\n",
      "166/166 [==============================] - 0s 196us/step - loss: 9.9945e-04\n",
      "Epoch 805/1000\n",
      "166/166 [==============================] - 0s 184us/step - loss: 0.0010\n",
      "Epoch 806/1000\n",
      "166/166 [==============================] - 0s 180us/step - loss: 0.0011\n",
      "Epoch 807/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0010\n",
      "Epoch 808/1000\n",
      "166/166 [==============================] - 0s 203us/step - loss: 0.0010\n",
      "Epoch 809/1000\n",
      "166/166 [==============================] - 0s 191us/step - loss: 0.0010\n",
      "Epoch 810/1000\n",
      "166/166 [==============================] - 0s 190us/step - loss: 0.0010\n",
      "Epoch 811/1000\n",
      "166/166 [==============================] - 0s 192us/step - loss: 0.0010\n",
      "Epoch 812/1000\n",
      "166/166 [==============================] - 0s 205us/step - loss: 0.0010\n",
      "Epoch 813/1000\n",
      "166/166 [==============================] - 0s 200us/step - loss: 0.0010\n",
      "Epoch 814/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 0.0010\n",
      "Epoch 815/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0010\n",
      "Epoch 816/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0010\n",
      "Epoch 817/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0010\n",
      "Epoch 818/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0010\n",
      "Epoch 819/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0010\n",
      "Epoch 820/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0010\n",
      "Epoch 821/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0010\n",
      "Epoch 822/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0010\n",
      "Epoch 823/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0010\n",
      "Epoch 824/1000\n",
      "166/166 [==============================] - 0s 220us/step - loss: 0.0010\n",
      "Epoch 825/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0010\n",
      "Epoch 826/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0010\n",
      "Epoch 827/1000\n",
      "166/166 [==============================] - 0s 192us/step - loss: 9.9980e-04\n",
      "Epoch 828/1000\n",
      "166/166 [==============================] - 0s 195us/step - loss: 0.0010\n",
      "Epoch 829/1000\n",
      "166/166 [==============================] - 0s 186us/step - loss: 0.0010\n",
      "Epoch 830/1000\n",
      "166/166 [==============================] - 0s 186us/step - loss: 0.0010\n",
      "Epoch 831/1000\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.001 - 0s 186us/step - loss: 0.0010\n",
      "Epoch 832/1000\n",
      "166/166 [==============================] - 0s 185us/step - loss: 0.0011\n",
      "Epoch 833/1000\n",
      "166/166 [==============================] - 0s 190us/step - loss: 0.0010\n",
      "Epoch 834/1000\n",
      "166/166 [==============================] - 0s 188us/step - loss: 0.0010\n",
      "Epoch 835/1000\n",
      "166/166 [==============================] - 0s 184us/step - loss: 0.0010\n",
      "Epoch 836/1000\n",
      "166/166 [==============================] - 0s 180us/step - loss: 0.0010\n",
      "Epoch 837/1000\n",
      "166/166 [==============================] - 0s 180us/step - loss: 9.9559e-04\n",
      "Epoch 838/1000\n",
      "166/166 [==============================] - 0s 182us/step - loss: 0.0011\n",
      "Epoch 839/1000\n",
      "166/166 [==============================] - 0s 200us/step - loss: 0.0010\n",
      "Epoch 840/1000\n",
      "166/166 [==============================] - 0s 198us/step - loss: 0.0010\n",
      "Epoch 841/1000\n",
      "166/166 [==============================] - 0s 199us/step - loss: 0.0010\n",
      "Epoch 842/1000\n",
      "166/166 [==============================] - ETA: 0s - loss: 0.001 - 0s 196us/step - loss: 0.0010\n",
      "Epoch 843/1000\n",
      "166/166 [==============================] - 0s 200us/step - loss: 0.0010\n",
      "Epoch 844/1000\n",
      "166/166 [==============================] - 0s 198us/step - loss: 0.0010\n",
      "Epoch 845/1000\n",
      "166/166 [==============================] - 0s 189us/step - loss: 0.0010\n",
      "Epoch 846/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0010\n",
      "Epoch 847/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 0s 200us/step - loss: 9.9339e-04\n",
      "Epoch 848/1000\n",
      "166/166 [==============================] - 0s 187us/step - loss: 0.0010\n",
      "Epoch 849/1000\n",
      "166/166 [==============================] - 0s 197us/step - loss: 0.0010\n",
      "Epoch 850/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0011\n",
      "Epoch 851/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0010\n",
      "Epoch 852/1000\n",
      "166/166 [==============================] - 0s 205us/step - loss: 0.0010\n",
      "Epoch 853/1000\n",
      "166/166 [==============================] - 0s 205us/step - loss: 9.9551e-04\n",
      "Epoch 854/1000\n",
      "166/166 [==============================] - 0s 203us/step - loss: 0.0010\n",
      "Epoch 855/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0010\n",
      "Epoch 856/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0010\n",
      "Epoch 857/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0010\n",
      "Epoch 858/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0010\n",
      "Epoch 859/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0010\n",
      "Epoch 860/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0010\n",
      "Epoch 861/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0010\n",
      "Epoch 862/1000\n",
      "166/166 [==============================] - 0s 204us/step - loss: 9.9637e-04\n",
      "Epoch 863/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0010\n",
      "Epoch 864/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0010\n",
      "Epoch 865/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0010\n",
      "Epoch 866/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0010\n",
      "Epoch 867/1000\n",
      "166/166 [==============================] - 0s 203us/step - loss: 0.0010\n",
      "Epoch 868/1000\n",
      "166/166 [==============================] - 0s 190us/step - loss: 0.0010\n",
      "Epoch 869/1000\n",
      "166/166 [==============================] - 0s 186us/step - loss: 0.0010\n",
      "Epoch 870/1000\n",
      "166/166 [==============================] - 0s 187us/step - loss: 0.0010\n",
      "Epoch 871/1000\n",
      "166/166 [==============================] - 0s 185us/step - loss: 0.0011\n",
      "Epoch 872/1000\n",
      "166/166 [==============================] - 0s 198us/step - loss: 0.0010\n",
      "Epoch 873/1000\n",
      "166/166 [==============================] - 0s 182us/step - loss: 9.9585e-04\n",
      "Epoch 874/1000\n",
      "166/166 [==============================] - 0s 197us/step - loss: 0.0010\n",
      "Epoch 875/1000\n",
      "166/166 [==============================] - 0s 192us/step - loss: 0.0010\n",
      "Epoch 876/1000\n",
      "166/166 [==============================] - 0s 202us/step - loss: 9.9546e-04\n",
      "Epoch 877/1000\n",
      "166/166 [==============================] - 0s 192us/step - loss: 0.0010\n",
      "Epoch 878/1000\n",
      "166/166 [==============================] - 0s 193us/step - loss: 0.0010\n",
      "Epoch 879/1000\n",
      "166/166 [==============================] - 0s 184us/step - loss: 9.9634e-04\n",
      "Epoch 880/1000\n",
      "166/166 [==============================] - 0s 191us/step - loss: 0.0010\n",
      "Epoch 881/1000\n",
      "166/166 [==============================] - 0s 195us/step - loss: 0.0010\n",
      "Epoch 882/1000\n",
      "166/166 [==============================] - 0s 189us/step - loss: 0.0010\n",
      "Epoch 883/1000\n",
      "166/166 [==============================] - 0s 191us/step - loss: 0.0010\n",
      "Epoch 884/1000\n",
      "166/166 [==============================] - 0s 195us/step - loss: 9.9775e-04\n",
      "Epoch 885/1000\n",
      "166/166 [==============================] - 0s 195us/step - loss: 0.0010\n",
      "Epoch 886/1000\n",
      "166/166 [==============================] - 0s 204us/step - loss: 0.0010\n",
      "Epoch 887/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0010\n",
      "Epoch 888/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0010\n",
      "Epoch 889/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0010\n",
      "Epoch 890/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0010\n",
      "Epoch 891/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0010\n",
      "Epoch 892/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0010\n",
      "Epoch 893/1000\n",
      "166/166 [==============================] - 0s 205us/step - loss: 9.8020e-04\n",
      "Epoch 894/1000\n",
      "166/166 [==============================] - 0s 199us/step - loss: 0.0011\n",
      "Epoch 895/1000\n",
      "166/166 [==============================] - 0s 205us/step - loss: 0.0010\n",
      "Epoch 896/1000\n",
      "166/166 [==============================] - 0s 200us/step - loss: 0.0010\n",
      "Epoch 897/1000\n",
      "166/166 [==============================] - 0s 193us/step - loss: 0.0010\n",
      "Epoch 898/1000\n",
      "166/166 [==============================] - 0s 203us/step - loss: 0.0010\n",
      "Epoch 899/1000\n",
      "166/166 [==============================] - 0s 201us/step - loss: 9.9446e-04\n",
      "Epoch 900/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0010\n",
      "Epoch 901/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0010\n",
      "Epoch 902/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0010\n",
      "Epoch 903/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 0.0010\n",
      "Epoch 904/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0011\n",
      "Epoch 905/1000\n",
      "166/166 [==============================] - 0s 222us/step - loss: 0.0010\n",
      "Epoch 906/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0011\n",
      "Epoch 907/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0010\n",
      "Epoch 908/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0010\n",
      "Epoch 909/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0011\n",
      "Epoch 910/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0010\n",
      "Epoch 911/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0010\n",
      "Epoch 912/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 9.9559e-04\n",
      "Epoch 913/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0010\n",
      "Epoch 914/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0010\n",
      "Epoch 915/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0011\n",
      "Epoch 916/1000\n",
      "166/166 [==============================] - 0s 221us/step - loss: 9.9222e-04\n",
      "Epoch 917/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0010\n",
      "Epoch 918/1000\n",
      "166/166 [==============================] - 0s 225us/step - loss: 0.0010\n",
      "Epoch 919/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0010\n",
      "Epoch 920/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0010\n",
      "Epoch 921/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0010\n",
      "Epoch 922/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0010\n",
      "Epoch 923/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0010\n",
      "Epoch 924/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 9.9976e-04\n",
      "Epoch 925/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0010\n",
      "Epoch 926/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 9.9567e-04\n",
      "Epoch 927/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0010\n",
      "Epoch 928/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0010\n",
      "Epoch 929/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0010\n",
      "Epoch 930/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 9.9631e-04\n",
      "Epoch 931/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0010\n",
      "Epoch 932/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0010\n",
      "Epoch 933/1000\n",
      "166/166 [==============================] - 0s 205us/step - loss: 9.9192e-04\n",
      "Epoch 934/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0010\n",
      "Epoch 935/1000\n",
      "166/166 [==============================] - 0s 205us/step - loss: 9.9915e-04\n",
      "Epoch 936/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0010\n",
      "Epoch 937/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0010\n",
      "Epoch 938/1000\n",
      "166/166 [==============================] - 0s 197us/step - loss: 0.0010\n",
      "Epoch 939/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0010\n",
      "Epoch 940/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 0s 214us/step - loss: 9.9698e-04\n",
      "Epoch 941/1000\n",
      "166/166 [==============================] - 0s 199us/step - loss: 0.0010\n",
      "Epoch 942/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0010\n",
      "Epoch 943/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0010\n",
      "Epoch 944/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 9.9948e-04\n",
      "Epoch 945/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0010\n",
      "Epoch 946/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0010\n",
      "Epoch 947/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0010\n",
      "Epoch 948/1000\n",
      "166/166 [==============================] - 0s 225us/step - loss: 0.0010\n",
      "Epoch 949/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 9.9611e-04\n",
      "Epoch 950/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 9.9932e-04\n",
      "Epoch 951/1000\n",
      "166/166 [==============================] - 0s 200us/step - loss: 9.9369e-04\n",
      "Epoch 952/1000\n",
      "166/166 [==============================] - 0s 201us/step - loss: 0.0010\n",
      "Epoch 953/1000\n",
      "166/166 [==============================] - 0s 205us/step - loss: 0.0010\n",
      "Epoch 954/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0010\n",
      "Epoch 955/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0010\n",
      "Epoch 956/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 0.0010\n",
      "Epoch 957/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0010\n",
      "Epoch 958/1000\n",
      "166/166 [==============================] - 0s 213us/step - loss: 9.9737e-04\n",
      "Epoch 959/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0010\n",
      "Epoch 960/1000\n",
      "166/166 [==============================] - 0s 211us/step - loss: 0.0010\n",
      "Epoch 961/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 9.9395e-04\n",
      "Epoch 962/1000\n",
      "166/166 [==============================] - 0s 206us/step - loss: 0.0010\n",
      "Epoch 963/1000\n",
      "166/166 [==============================] - 0s 205us/step - loss: 0.0010\n",
      "Epoch 964/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0010\n",
      "Epoch 965/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 9.9051e-04\n",
      "Epoch 966/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0010\n",
      "Epoch 967/1000\n",
      "166/166 [==============================] - 0s 205us/step - loss: 0.0011\n",
      "Epoch 968/1000\n",
      "166/166 [==============================] - 0s 208us/step - loss: 0.0010\n",
      "Epoch 969/1000\n",
      "166/166 [==============================] - 0s 204us/step - loss: 0.0010\n",
      "Epoch 970/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0010\n",
      "Epoch 971/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0010\n",
      "Epoch 972/1000\n",
      "166/166 [==============================] - 0s 221us/step - loss: 0.0010\n",
      "Epoch 973/1000\n",
      "166/166 [==============================] - 0s 210us/step - loss: 0.0010\n",
      "Epoch 974/1000\n",
      "166/166 [==============================] - 0s 212us/step - loss: 0.0010\n",
      "Epoch 975/1000\n",
      "166/166 [==============================] - 0s 214us/step - loss: 0.0010\n",
      "Epoch 976/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0010\n",
      "Epoch 977/1000\n",
      "166/166 [==============================] - 0s 207us/step - loss: 0.0010\n",
      "Epoch 978/1000\n",
      "166/166 [==============================] - 0s 202us/step - loss: 9.9009e-04\n",
      "Epoch 979/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 0.0011\n",
      "Epoch 980/1000\n",
      "166/166 [==============================] - 0s 205us/step - loss: 9.9818e-04\n",
      "Epoch 981/1000\n",
      "166/166 [==============================] - 0s 218us/step - loss: 9.9328e-04\n",
      "Epoch 982/1000\n",
      "166/166 [==============================] - 0s 216us/step - loss: 0.0010\n",
      "Epoch 983/1000\n",
      "166/166 [==============================] - 0s 215us/step - loss: 0.0011\n",
      "Epoch 984/1000\n",
      "166/166 [==============================] - 0s 219us/step - loss: 9.9469e-04\n",
      "Epoch 985/1000\n",
      "166/166 [==============================] - 0s 209us/step - loss: 9.9362e-04\n",
      "Epoch 986/1000\n",
      "166/166 [==============================] - 0s 223us/step - loss: 0.0010\n",
      "Epoch 987/1000\n",
      "166/166 [==============================] - 0s 222us/step - loss: 0.0010\n",
      "Epoch 988/1000\n",
      "166/166 [==============================] - 0s 217us/step - loss: 0.0010\n",
      "Epoch 989/1000\n",
      "166/166 [==============================] - 0s 204us/step - loss: 0.0010\n",
      "Epoch 990/1000\n",
      "166/166 [==============================] - 0s 181us/step - loss: 0.0010\n",
      "Epoch 991/1000\n",
      "166/166 [==============================] - 0s 186us/step - loss: 0.0010\n",
      "Epoch 992/1000\n",
      "166/166 [==============================] - 0s 173us/step - loss: 0.0010\n",
      "Epoch 993/1000\n",
      "166/166 [==============================] - 0s 186us/step - loss: 0.0010\n",
      "Epoch 994/1000\n",
      "166/166 [==============================] - 0s 181us/step - loss: 9.9706e-04\n",
      "Epoch 995/1000\n",
      "166/166 [==============================] - 0s 193us/step - loss: 0.0010\n",
      "Epoch 996/1000\n",
      "166/166 [==============================] - 0s 188us/step - loss: 0.0010\n",
      "Epoch 997/1000\n",
      "166/166 [==============================] - 0s 180us/step - loss: 9.9901e-04\n",
      "Epoch 998/1000\n",
      "166/166 [==============================] - 0s 182us/step - loss: 0.0010\n",
      "Epoch 999/1000\n",
      "166/166 [==============================] - 0s 185us/step - loss: 0.0010\n",
      "Epoch 1000/1000\n",
      "166/166 [==============================] - 0s 184us/step - loss: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a27fa5128>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=1000, batch_size=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate predictions for training\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error = 0.001002538257070918\n",
      "testing error = 0.0032318224903286957\n"
     ]
    }
   ],
   "source": [
    "# print out training and testing errors\n",
    "training_error = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('training error = ' + str(training_error))\n",
    "\n",
    "testing_error = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('testing error = ' + str(testing_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAEKCAYAAAACZ2ynAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njTHGmCBlSdwYY4wJUv8fUi/CA0L1h8UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a28005b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Plot everything - the original series as well as predictions on training and testing sets\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plot original series\n",
    "plt.plot(dataset,color = 'k')\n",
    "\n",
    "# plot training set prediction\n",
    "split_pt = train_test_split + window_size \n",
    "plt.plot(np.arange(window_size,split_pt,1),train_predict,color = 'b')\n",
    "\n",
    "# plot testing set prediction\n",
    "plt.plot(np.arange(split_pt,split_pt + len(test_predict),1),test_predict,color = 'r')\n",
    "\n",
    "# pretty up graph\n",
    "plt.xlabel('day')\n",
    "plt.ylabel('(normalized) price of stock')\n",
    "plt.legend(['original series','training fit','testing fit'],loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text classification from IMDB dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another task where you can use neural networks is a text classification (or text processing). For this example we are going to use the IMDB dataset, which is also part of Keras. This dataset contains IMDB reviews and tells whether they are positive or negative. Lets load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=5000)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
      "label: 1\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(\"label: {}\".format(y_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see we have received just an array of numbers, nothing else. These are actually indexes of words, where the words are indexed by how most common they are in the whole dataset. So index 4 means that this was the 4th most common word in the dataset. The labels are either 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "max_features = 5000\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the sequences have different lengths, we need to pad them to be on the same length (400 words in our case). For this Keras has some helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 400)\n",
      "x_test shape: (25000, 400)\n"
     ]
    }
   ],
   "source": [
    "maxlen = 400\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    1  194 1153  194    2   78  228    5    6 1463 4369    2  134\n",
      "   26    4  715    8  118 1634   14  394   20   13  119  954  189  102\n",
      "    5  207  110 3103   21   14   69  188    8   30   23    7    4  249\n",
      "  126   93    4  114    9 2300 1523    5  647    4  116    9   35    2\n",
      "    4  229    9  340 1322    4  118    9    4  130 4901   19    4 1002\n",
      "    5   89   29  952   46   37    4  455    9   45   43   38 1543 1905\n",
      "  398    4 1649   26    2    5  163   11 3215    2    4 1153    9  194\n",
      "  775    7    2    2  349 2637  148  605    2    2   15  123  125   68\n",
      "    2    2   15  349  165 4362   98    5    4  228    9   43    2 1157\n",
      "   15  299  120    5  120  174   11  220  175  136   50    9 4373  228\n",
      "    2    5    2  656  245 2350    5    4    2  131  152  491   18    2\n",
      "   32    2 1212   14    9    6  371   78   22  625   64 1382    9    8\n",
      "  168  145   23    4 1690   15   16    4 1355    5   28    6   52  154\n",
      "  462   33   89   78  285   16  145   95]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define our neural network model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a firsts layer we will have an Embedding layer. This is a very interesting one, because its purpose is to learn good mathematical representation of the words. But good for what? Well good for our specific task and good for our neural network - in a different neural network or with different data, the Embedding layer will actually learn something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n",
    "\n",
    "# Dropout layer to avoid overfitting\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next layers should learn to capture the relations between the words. For this we can use a dense layer (has many connections, so slow learning), LSTM (also quite slow to learn), or a convolutional layer. This is similar like in the image classification, but we will have just 1D convolution:\n",
    "\n",
    "![1D Convolution](conv1d.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we add a Convolution1D, which will learn filters\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll add a couple of standard dense layers and dropouts. Please note that the last layer is just sigmoid layer - we'll have only 0 or 1 as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we use max pooling:\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 400, 50)           250000    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 400, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 398, 250)          37750     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 350,751\n",
      "Trainable params: 350,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets train the network, two epochs are quite enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 90s 4ms/step - loss: 0.4034 - acc: 0.8026 - val_loss: 0.3186 - val_acc: 0.8622\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 87s 3ms/step - loss: 0.2300 - acc: 0.9066 - val_loss: 0.3030 - val_acc: 0.8730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3847fdd8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now do some predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x_test[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[0:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
