{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Practices for neural networks\n",
    "\n",
    "| What people think they will do                                                            | What they actually do                                                                            |\n",
    "| ----------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------ |\n",
    "| Build crazy neural nets                                                                   | Detect and correct imaging artifacts. Seriously... this is like half the job.                    |\n",
    "| Build the next great machine learning system                                              | Getting the damn sensor to run reliably and cleanly.                                             |\n",
    "| Deep learning, deep learning, deep learning, deep learning,                               | Spends hours on Figure 8 building data sets. Then hours more scrubbing the data.                 |\n",
    "| deep learning, deep learning, deep learning, deep learning, deep learning, deep learning, | Moving gigs of data between S3 buckets.                                                          |\n",
    "| deep learning, deep learning, deep learning, deep learning,                               | Build infrastracture to build, deploy, version, track, and validate models.                      |\n",
    "| deep learning, deep learning, deep learning, deep learning, deep learning, deep learning, | Sit in boring meetings with product managers explaining precision and recall for the third time. |\n",
    "| deep learning, deep learning,                                                             | Getting matplotlib to work right.                                                              |\n",
    "\n",
    "So some best practices and hints.\n",
    "\n",
    "### Get as much data as possible\n",
    "\n",
    "There are only few examples of machine learning algorithms that require low amounts of data. If you want accuracy, if you want performance, you need as much data as possible.\n",
    "\n",
    "### Get unbiased data\n",
    "\n",
    "Bias in data is bad. Imagine that you train your neural network to recognize dogs. But because you didn't had images of poodles, your network will not learn to recognize those. Or because all your pictures have been taken in night, you won't recognize them during the day. This can happen to you all the time, and can have serious consequences.\n",
    "\n",
    "### Never Fake Data\n",
    "\n",
    "In practice, you will always find your self between unsuficient data for your project and a manager telling you \"fake it\" or \"generate it\". There are real cases when someone got an awesome idea to generate testing data. It will never work. There is always something (at least in big data), in real world, that one can never think about. So using real data (a lot of them) will always give you proper results, while doing anything on faked (or generated) data, will only lead you to something that is useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
